{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import matplotlib as mpl\n",
    "import imageio\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [tryint(c) for c in re.split('([0-9]+)', s)]\n",
    "\n",
    "\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    \n",
    "def arr2bytes(arr):\n",
    "    \"\"\"Display a 2- or 3-d numpy array as an image.\"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        format, cmap = 'png', mpl.cm.gray\n",
    "    elif arr.ndim == 3:\n",
    "        format, cmap = 'jpg', None\n",
    "    else:\n",
    "        raise ValueError(\"Only 2- or 3-d arrays can be displayed as images.\")\n",
    "    # Don't let matplotlib autoscale the color range so we can control overall luminosity\n",
    "    vmax = 255 if arr.dtype == 'uint8' else 1.0\n",
    "    with BytesIO() as buffer:\n",
    "        mpl.image.imsave(buffer, arr, format=format, cmap=cmap, vmin=0, vmax=vmax)\n",
    "        out = buffer.getvalue()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions to create the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters for drawing the map\n",
    "\n",
    "# The values correspond to the values we will plot the map with.\n",
    "\n",
    "WALL_MAP_VALUE = 1\n",
    "REWARD_MAP_VALUE = 2\n",
    "EXIT_MAP_VALUE = 3\n",
    "\n",
    "\n",
    "REWARD_SPARSITY = 0.1  \n",
    "\n",
    "# The reward sparsity controls how many pixels will contain rewards. A reward sparsity of 0.1 means about 10% of the \n",
    "# pixels on average will contain rewards.                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the report, we refer to a corridor with the term \"room\". The two terms are interchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     31
    ]
   },
   "outputs": [],
   "source": [
    "def create_corridor(CORRIDOR_SHAPE, SEED = 42):\n",
    "    \"\"\"creates an array corresponding to a corridor of the level\"\"\"\n",
    "    # instantiate corridor with rewards\n",
    "    np.random.seed(SEED)\n",
    "    corridor = np.random.choice([REWARD_MAP_VALUE, 0], size = CORRIDOR_SHAPE, p = [REWARD_SPARSITY, 1-REWARD_SPARSITY])\n",
    "\n",
    "    # add walls\n",
    "    SPACE = 5\n",
    "    GAP = 2\n",
    "    GAP_UP = -1\n",
    "    GAP_DOWN = -2\n",
    "\n",
    "    wall_x = SPACE\n",
    "    orientation = GAP_UP\n",
    "\n",
    "    while wall_x < CORRIDOR_SHAPE[0]:\n",
    "        if orientation == GAP_UP: \n",
    "            corridor[wall_x, GAP:] = WALL_MAP_VALUE\n",
    "            orientation = GAP_DOWN\n",
    "        elif orientation == GAP_DOWN:\n",
    "            corridor[wall_x, :-GAP] = WALL_MAP_VALUE\n",
    "            orientation = GAP_UP\n",
    "        wall_x += SPACE\n",
    "        \n",
    "    # place exit at the end of corridor and remove existing walls\n",
    "    corridor[-1, :] = 0\n",
    "    corridor[-1, CORRIDOR_SHAPE[1]//2] = EXIT_MAP_VALUE\n",
    "    \n",
    "        \n",
    "    return corridor\n",
    "\n",
    "def create_map(CORRIDOR_SHAPE, corridors):\n",
    "    \"\"\"creates a map from a list of corridors.\"\"\"\n",
    "    size = 2*CORRIDOR_SHAPE[0] + CORRIDOR_SHAPE[1] \n",
    "    center_xy = int((size - 1)/ 2)\n",
    "    \n",
    "    terrain = np.ones((size, size))\n",
    "    \n",
    "    # add right corridor\n",
    "    if True:\n",
    "        i = 0\n",
    "        start_x  = int(center_xy + (CORRIDOR_SHAPE[1])/2) + 1\n",
    "        end_x = int(start_x + CORRIDOR_SHAPE[0])\n",
    "\n",
    "        start_y = int(center_xy - (CORRIDOR_SHAPE[1]-1)/2)\n",
    "        end_y = int(start_y + CORRIDOR_SHAPE[1])\n",
    "\n",
    "        terrain[start_x:end_x, start_y : end_y] = rotate(corridors[i], angle = 90*i)\n",
    "    \n",
    "    # add top corridor\n",
    "    if True:\n",
    "        i = 1\n",
    "        start_x  = int(center_xy - (CORRIDOR_SHAPE[1]-1)/2)\n",
    "        end_x = int(start_x + CORRIDOR_SHAPE[1])\n",
    "\n",
    "        start_y = int(center_xy + (CORRIDOR_SHAPE[1]-1)/2) + 1\n",
    "        end_y = int(start_y + CORRIDOR_SHAPE[0])\n",
    "\n",
    "        terrain[start_x:end_x, start_y : end_y] = rotate(corridors[i], angle = 90*i)\n",
    "\n",
    "    # add left corridor\n",
    "    if True:\n",
    "        i = 2\n",
    "        start_x  = 0\n",
    "        end_x = int(start_x + CORRIDOR_SHAPE[0])\n",
    "\n",
    "        start_y = int(center_xy - (CORRIDOR_SHAPE[1]-1)/2) \n",
    "        end_y = int(start_y + CORRIDOR_SHAPE[1])\n",
    "\n",
    "        terrain[start_x:end_x, start_y : end_y] = rotate(corridors[i], angle = 90*i)\n",
    "\n",
    "    # add bottom corridor\n",
    "    if True:\n",
    "        i = 3\n",
    "        start_x  = int(center_xy - (CORRIDOR_SHAPE[1]-1)/2)\n",
    "        end_x = int(start_x + CORRIDOR_SHAPE[1])\n",
    "\n",
    "        end_y = int(center_xy - (CORRIDOR_SHAPE[1]-1)/2)\n",
    "        start_y = int(start_y - CORRIDOR_SHAPE[0])\n",
    "\n",
    "        terrain[start_x:end_x, start_y : end_y] = rotate(corridors[i], angle = 90*i)\n",
    "  \n",
    "    # add Fork from starting position\n",
    "    if True:\n",
    "        terrain[center_xy , center_xy - CORRIDOR_SHAPE[1]//2: center_xy + CORRIDOR_SHAPE[1] //2 + 1] = 0\n",
    "        terrain[center_xy - CORRIDOR_SHAPE[1]//2: center_xy + CORRIDOR_SHAPE[1] //2 + 1, center_xy] = 0\n",
    "        \n",
    "    return terrain\n",
    "    \n",
    "def create_env(CORRIDOR_SHAPE, SEEDS = [42, 43, 44, 45]):\n",
    "    \"\"\"creates both the corridors and the map.\"\"\"\n",
    "    corridors = [create_corridor(CORRIDOR_SHAPE, SEEDS[i]) for i in range(4)]\n",
    "    env = create_map(CORRIDOR_SHAPE, corridors)\n",
    "    return env\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of maps we can generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEEDS = [42, 43, 44, 45]\n",
    "CORRIDOR_SHAPE = (21, 11) # should be odd numbers for perfect symmetry\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "env = create_env((11, 5), SEEDS)\n",
    "plt.imshow(rotate(env, angle= 90))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "env = create_env((21, 11), SEEDS)\n",
    "plt.imshow(rotate(env, angle= 90))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "env = create_env((31, 21), SEEDS)\n",
    "plt.imshow(rotate(env, angle= 90))\n",
    "plt.axis('off')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(30,10)\n",
    "plt.savefig(\"procedural_environments.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow = Exit,     Green = Rewards,  Blue = Walls (unexplorable coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corridors = [create_corridor(CORRIDOR_SHAPE, SEEDS[i]) for i in range(4)]\n",
    "for i, corridor in enumerate(corridors):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(rotate(corridor.T, angle = 90*i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, CORRIDOR_SHAPE):\n",
    "        # The agent's location is initialized in the middle of the map\n",
    "        size = 2*CORRIDOR_SHAPE[0] + CORRIDOR_SHAPE[1] \n",
    "        center_xy = int((size - 1)/ 2)\n",
    "        self.x = center_xy\n",
    "        self.y = center_xy\n",
    "    \n",
    "    def action(self, choice):\n",
    "        if choice == 0:\n",
    "            # go left\n",
    "            self.__move__(-1, 0)\n",
    "        if choice == 1:\n",
    "            # go up\n",
    "            self.__move__(0, 1)\n",
    "        if choice == 2:\n",
    "            # go right:\n",
    "            self.__move__(1, 0)\n",
    "        if choice == 3:\n",
    "            # go down\n",
    "            self.__move__(0, -1)\n",
    "        return\n",
    "    \n",
    "    def __move__(self, x, y):\n",
    "        self.x += x\n",
    "        self.y += y\n",
    "        return\n",
    "    \n",
    "    def get_coords(self):\n",
    "        return (self.x, self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Phase1 class for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Phase1():\n",
    "    def __init__(self, CORRIDOR_SHAPE = (21, 11), SEEDS = [42, 43, 44, 45]):\n",
    "        # HYPERPARAMETERS\n",
    "        self.EXPLORE_ITER          = 200\n",
    "        self.W1                    = 1    # weight of # of times chosen attribute\n",
    "        self.W2                    = 1    # weight of # of times seen attribute\n",
    "        self.W3                    = 1    # weight of # of times chosen since it has led to a new discovery attribute\n",
    "        self.P1                    = 2    \n",
    "        self.P2                    = 2    # powers of the attributes\n",
    "        self.P3                    = 2\n",
    "        self.E1                    = 1e-1   # constants for numerical stability. They avoid divison by 0 \n",
    "        self.E2                    = 1e-1   # and make sure the probability of choosing a cell is never 0.\n",
    "        self.WN_HORIZONTAL         = 10\n",
    "        self.WN_VERTICAL           = 10     # weights of the neighbors used for computing\n",
    "        self.WN_REWARD             = 100    # the Neighbor Score of a cell\n",
    "        \n",
    "        # Initialization\n",
    "        self.env = create_env(CORRIDOR_SHAPE, SEEDS)\n",
    "        self.MAX_SCORE = len(np.where(self.env == REWARD_MAP_VALUE)[0])\n",
    "        self.agent = Agent(CORRIDOR_SHAPE = CORRIDOR_SHAPE)\n",
    "        self.archive = {}               # contains the trajectory of actions leading to a cell\n",
    "        self.cell_attributes = {}       # contains the three attributes of the cells\n",
    "        self.cell_scores = {}           # contains the cell scores\n",
    "        self.cell_states = {}           # contains the state of the environment and the position of the agent\n",
    "        self.cell_cumulative_scores = {} # contains the cumulative score obtained at a given cell\n",
    "        self.xys = {}\n",
    "        \n",
    "        # Add initial cell in the middle of the map to the archive\n",
    "        size = 2*CORRIDOR_SHAPE[0] + CORRIDOR_SHAPE[1] \n",
    "        center_xy = int((size - 1)/ 2)\n",
    "        cell_key = \"{},{}\".format(center_xy, center_xy)\n",
    "        \n",
    "        self.archive[cell_key] = []\n",
    "        self.cell_attributes[cell_key] = [0, 0, 0]\n",
    "        self.cell_scores[cell_key] = 1\n",
    "        self.cell_states[cell_key] = [self.env.copy(), self.agent.get_coords()]\n",
    "        self.cell_cumulative_scores[cell_key] = 0\n",
    "        self.xys[cell_key] = [(center_xy, center_xy)]\n",
    "        \n",
    "    def choose_cell(self):\n",
    "        \"\"\"Chooses a cell randomly from the archive thanks to cell scores.\"\"\"\n",
    "        # reset seed\n",
    "        np.random.seed()\n",
    "        \n",
    "        keys = list(self.cell_scores.keys())\n",
    "        scores = list(self.cell_scores.values())\n",
    "        \n",
    "        chosen_cell_key = np.random.choice(keys, size = 1, p = scores)[0]\n",
    "        chosen_cell_x = chosen_cell_key.split(',')[0]\n",
    "        chosen_cell_y = chosen_cell_key.split(',')[1]\n",
    "        \n",
    "        # update number of times a cell has been chosen as a cell to explore from\n",
    "        self.cell_attributes[chosen_cell_key][0] += 1\n",
    "        \n",
    "        return (chosen_cell_x, chosen_cell_y)\n",
    "    \n",
    "    def store_cell(self, c, trajectory, cumulative_score, agent_xy):\n",
    "        \"\"\"Adds a cell c and the trajectory of actions that led to c to the archive.\"\"\"\n",
    "        cell_key = \"{},{}\".format(c[0], c[1])\n",
    "        \n",
    "        self.xys[cell_key] = agent_xy.copy()\n",
    "        self.archive[cell_key] = trajectory.copy()\n",
    "        self.cell_cumulative_scores[cell_key] = cumulative_score\n",
    "        self.cell_states[cell_key] = [self.env.copy(), self.agent.get_coords()]\n",
    "        \n",
    "        try:\n",
    "            # assert if cell was already in the archive. This is done to keep the attributes of the cell intact.\n",
    "            len(self.cell_attributes[cell_key])\n",
    "        except:\n",
    "            # if the cell was not in the archive then we set its attributes to 0 and its score to 0\n",
    "            self.cell_attributes[cell_key] = [0, 0, 0]\n",
    "            self.cell_scores[cell_key] = 0\n",
    "            \n",
    "        return\n",
    "        \n",
    "    def should_store(self, c, trajectory, cumulative_score, agent_xy):\n",
    "        \"\"\"Assesses whether a cell c and the trajectory of actions that led to c shoud be stored in the archive.\"\"\"\n",
    "        cell_key = \"{},{}\".format(c[0], c[1])\n",
    "        \n",
    "        # if the cell was not in the archive it should be stored.\n",
    "        if not cell_key in list(self.archive.keys()):\n",
    "            return True\n",
    "        \n",
    "        # if the cell was already in the archive then it should be added if \n",
    "        #    i) the trajectory is shorter\n",
    "        #   ii) the cumulative score is higher\n",
    "\n",
    "        length_old_trajectory = len(self.xys[cell_key])\n",
    "        length_new_trajectory = len(agent_xy)\n",
    "\n",
    "        if length_new_trajectory < length_old_trajectory:\n",
    "            if cumulative_score >= self.cell_cumulative_scores[cell_key]:\n",
    "                return True\n",
    "\n",
    "        if cumulative_score > self.cell_cumulative_scores[cell_key]:\n",
    "            return True        \n",
    "        return False\n",
    "        \n",
    "        \n",
    "    def explore(self):\n",
    "        \"\"\"Launches exploration procedure.\"\"\"\n",
    "        # reset seed\n",
    "        np.random.seed()\n",
    "        \n",
    "        self.agent = Agent(self.env.shape)\n",
    "        starting_cell = self.choose_cell()\n",
    "        starting_cell_key = \"{},{}\".format(starting_cell[0], starting_cell[1])\n",
    "        \n",
    "        self.agent.x = self.cell_states[starting_cell_key][1][0]\n",
    "        self.agent.y = self.cell_states[starting_cell_key][1][1]\n",
    "        self.env = self.cell_states[starting_cell_key][0].copy()\n",
    "        cumulative_score = self.cell_cumulative_scores[starting_cell_key]\n",
    "        trajectory = self.archive[starting_cell_key].copy()\n",
    "        agent_xy = self.xys[starting_cell_key].copy()\n",
    "\n",
    "        has_discovered = False\n",
    "        \n",
    "        oob_x = np.where(self.env[0] == 1)[0]\n",
    "        oob_y = np.where(self.env[:,0] == 1)[0]\n",
    "\n",
    "        oob = []\n",
    "        for x in oob_x:\n",
    "            for y in oob_y:\n",
    "                oob.append((x, y))\n",
    "        \n",
    "        # Launch exploration\n",
    "        for k in range(self.EXPLORE_ITER):\n",
    "            # assess if oob\n",
    "            if (self.agent.x, self.agent.y) in oob:\n",
    "                print(\"OUT OF BOUNDS\")\n",
    "            \n",
    "            \n",
    "            # assess available actions\n",
    "            possible_actions, _ = self.get_possible_actions(self.agent.x, self.agent.y)\n",
    "            n = len(possible_actions)\n",
    "            \n",
    "            # choose an action randomly\n",
    "            choice = np.random.choice(possible_actions, size = 1, p = [1/n] * n)[0]\n",
    "            self.agent.action(choice)\n",
    "                        \n",
    "            # assess if agent has left the map\n",
    "            if self.env[self.agent.x, self.agent.y] == EXIT_MAP_VALUE:\n",
    "                break\n",
    "            \n",
    "            # update cell metadata\n",
    "            reward = self.get_reward()\n",
    "            if reward == 1:\n",
    "                cumulative_score += reward\n",
    "                self.env[self.agent.x, self.agent.y] = 0\n",
    "    \n",
    "            trajectory.append(choice)\n",
    "            agent_xy.append(self.agent.get_coords())\n",
    "            c = (self.agent.x, self.agent.y)\n",
    "            cell_key =\"{},{}\".format(c[0], c[1])\n",
    "            \n",
    "            # store cell\n",
    "            if self.should_store(c, trajectory, cumulative_score, agent_xy):\n",
    "                self.store_cell(c, trajectory, cumulative_score, agent_xy)\n",
    "                # reset number of times a cell has been chosen since it last produced the discovery of a new or better cell\n",
    "                self.cell_attributes[starting_cell_key][2] = 0\n",
    "                has_discovered = True\n",
    "            \n",
    "            # update number of times a cell was visited at any point during phase 1\n",
    "            self.cell_attributes[cell_key][1] += 1\n",
    "        ### END OF EXPLORATION\n",
    "        \n",
    "        # update number of times the starting cell has been chosen since it last produced the discovery of a new or better cell\n",
    "        if has_discovered == False:\n",
    "            self.cell_attributes[starting_cell_key][2] += 1\n",
    "        \n",
    "        self.compute_cell_scores()\n",
    "        return\n",
    "            \n",
    "    def get_reward(self):\n",
    "        \"\"\"\n",
    "        If the agent's location contains a reward, the reward is removed\n",
    "        from the map and the value of the reward is returned.\n",
    "        \"\"\"\n",
    "        x, y = self.agent.x, self.agent.y\n",
    "        if self.env[x, y] == REWARD_MAP_VALUE:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    def get_possible_actions(self, x, y):\n",
    "        \"\"\"\n",
    "        Assesses the possible actions available to the agent at location (x,y). For each action, \n",
    "        we assess if by taking this action the agent will still be in the bounds of the map\n",
    "        and if it will not land in the wall.\n",
    "        We also return the neighboring locations as they will be useful to compute the Neighbor Score\n",
    "        of each cell.\n",
    "        \n",
    "        \"\"\"        \n",
    "        choices = []\n",
    "        neighbors = []\n",
    "        if x - 1 >= 0:\n",
    "            if self.env[x-1, y] != WALL_MAP_VALUE:\n",
    "                choices.append(0)\n",
    "                neighbors.append((x-1, y))\n",
    "        \n",
    "        if y + 1 < self.env.shape[1]:\n",
    "            if self.env[x, y+1] != WALL_MAP_VALUE:\n",
    "                choices.append(1)\n",
    "                neighbors.append((x, y+1))\n",
    "        \n",
    "        if x + 1 < self.env.shape[0]:\n",
    "            if self.env[x+1, y] != WALL_MAP_VALUE:\n",
    "                choices.append(2)\n",
    "                neighbors.append((x+1, y))\n",
    "        \n",
    "        if y - 1 >= 0:\n",
    "            if self.env[x, y-1] != WALL_MAP_VALUE:\n",
    "                choices.append(3)\n",
    "                neighbors.append((x, y-1))\n",
    "                \n",
    "        return choices, neighbors\n",
    "    \n",
    "    def cell_count_score(self, c):\n",
    "        \"\"\"Computes the Count Score of a given cell.\"\"\"\n",
    "        cell_key = \"{},{}\".format(c[0], c[1])\n",
    "        attribute_values = np.array(self.cell_attributes[cell_key])\n",
    "        attribute_weights = np.array([self.W1, self.W2, self.W3])\n",
    "        attribute_powers = np.array([self.P1, self.P2, self.P3])\n",
    "        \n",
    "        scores = attribute_weights * ((attribute_values + self.E1)**-attribute_powers)\n",
    "        \n",
    "        return scores.sum() + self.E2\n",
    "        \n",
    "    def cell_neighbor_score(self, c):\n",
    "        \"\"\"Computes the Neighbor Score of a given cell.\"\"\"\n",
    "        _, neighbors = self.get_possible_actions(*c)\n",
    "        scores = np.zeros(4)\n",
    "        \n",
    "        for i,neighbor in enumerate(neighbors):\n",
    "            try:\n",
    "                neighbor_key = \"{},{}\".format(neighbor[0], neighbor[1])\n",
    "                len(self.archive[neighbor_key])\n",
    "            except:\n",
    "                # if this neighbor is new add associated score\n",
    "                if self.env[neighbor] == REWARD_MAP_VALUE:\n",
    "                    scores[i] = self.WN_REWARD\n",
    "                elif i == 0 or i == 2:\n",
    "                    scores[i] = self.WN_HORIZONTAL\n",
    "                else:\n",
    "                    scores[i] = self.WN_VERTICAL\n",
    "        return scores.sum()\n",
    "    \n",
    "    def compute_cell_scores(self):\n",
    "        \"\"\"Computes the scores of every cell in the archive.\"\"\"\n",
    "        cell_keys = list(self.archive.keys())\n",
    "        cell_scores = np.zeros(len(cell_keys))\n",
    "        \n",
    "        for i,cell_key in enumerate(cell_keys):\n",
    "            c = (int(cell_key.split(',')[0]), int(cell_key.split(',')[1]))\n",
    "            cell_scores[i] = self.cell_count_score(c) + self.cell_neighbor_score(c) + 1\n",
    "        \n",
    "        cell_scores = cell_scores / cell_scores.sum()\n",
    "        \n",
    "        for i, cell_key in enumerate(cell_keys):\n",
    "            self.cell_scores[cell_key] = cell_scores[i]        \n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     82,
     89,
     96
    ]
   },
   "outputs": [],
   "source": [
    "def get_best_trajectory(phase1):\n",
    "    \"\"\"Returns a the (x,y) tuples of the trajectory that got the best score\"\"\"\n",
    "    max_score = -1\n",
    "    cell = next(iter(phase1.cell_cumulative_scores.keys()))\n",
    "    for key, value in phase1.cell_cumulative_scores.items():\n",
    "        if value >= max_score and len(phase1.xys[key]) < len(phase1.xys[cell]):\n",
    "            cell = key\n",
    "        elif value > max_score:\n",
    "            max_score = value\n",
    "            cell = key\n",
    "\n",
    "    path = phase1.xys[cell]\n",
    "    real_trajectory_x = []\n",
    "    real_trajectory_y = []\n",
    "\n",
    "    for xy in path:\n",
    "        real_trajectory_x.append(xy[0])\n",
    "        real_trajectory_y.append(xy[1])\n",
    "\n",
    "    real_trajectory_x = tuple(real_trajectory_x)\n",
    "    real_trajectory_y = tuple(real_trajectory_y)\n",
    "\n",
    "    real_trajectory = tuple([real_trajectory_x, real_trajectory_y])\n",
    "    return real_trajectory\n",
    "\n",
    "def get_best_trajectory_matrix(phase1):\n",
    "    \"returns the best trajectory plotted on the map\"\n",
    "    max_score = -1\n",
    "    cell = next(iter(phase1.cell_cumulative_scores.keys()))\n",
    "    for key, value in phase1.cell_cumulative_scores.items():\n",
    "        if value >= max_score and len(phase1.xys[key]) < len(phase1.xys[cell]):\n",
    "            cell = key\n",
    "        elif value > max_score:\n",
    "            max_score = value\n",
    "            cell = key\n",
    "\n",
    "    path = phase1.xys[cell]\n",
    "    real_trajectory_x = []\n",
    "    real_trajectory_y = []\n",
    "\n",
    "    for xy in path:\n",
    "        real_trajectory_x.append(xy[0])\n",
    "        real_trajectory_y.append(xy[1])\n",
    "\n",
    "    real_trajectory_x = tuple(real_trajectory_x)\n",
    "    real_trajectory_y = tuple(real_trajectory_y)\n",
    "    real_trajectory = tuple([real_trajectory_x, real_trajectory_y])\n",
    "\n",
    "    env2 = phase1.cell_states[cell][0].copy()\n",
    "    env2[real_trajectory] = EXIT_MAP_VALUE\n",
    "    env2 = (env2 - env2.min()) / env2.max() * 255\n",
    "    return env2\n",
    "\n",
    "def get_neighbor_score_matrix(phase1):\n",
    "    \"returns the neighbor scores of the cells plotted against the map\"\n",
    "    score_matrix = np.zeros(phase1.env.shape)\n",
    "    for key in phase1.cell_scores.keys():\n",
    "        x = int(key.split(\",\")[0])\n",
    "        y = int(key.split(\",\")[1])\n",
    "        score_matrix[x, y] = phase1.cell_neighbor_score((x, y))\n",
    "\n",
    "    min_score = score_matrix[score_matrix > 0].min()\n",
    "    max_score = score_matrix.max()\n",
    "    score_matrix = (score_matrix - min_score) / max_score\n",
    "\n",
    "    return score_matrix\n",
    "\n",
    "def get_score_matrix(phase1):\n",
    "    \"returns the cell scores plotted against the map\"\n",
    "    score_matrix = np.zeros(phase1.env.shape)\n",
    "\n",
    "    for key, value in phase1.cell_scores.items():\n",
    "        x = int(key.split(\",\")[0])\n",
    "        y = int(key.split(\",\")[1])\n",
    "        score_matrix[x, y] = value\n",
    "\n",
    "    min_score = score_matrix[score_matrix > 0].min()\n",
    "    max_score = score_matrix.max()\n",
    "    # print(min_score, max_score)\n",
    "    score_matrix = (score_matrix - min_score) / max_score * 255\n",
    "    return score_matrix\n",
    "\n",
    "def save_score_matrix(phase1, i):\n",
    "    score_matrix = get_score_matrix(phase1)\n",
    "    score_matrix = np.array(Image.fromarray(score_matrix).resize((512, 512)))\n",
    "    path = \"./score_matrix/score_matrix_\" + str(i) + \".jpg\"\n",
    "    plt.imsave(path, score_matrix, cmap='gray')\n",
    "    return path\n",
    "\n",
    "def save_neighbor_score_matrix(phase1, i):\n",
    "    score_matrix = get_neighbor_score_matrix(phase1)\n",
    "    score_matrix = np.array(Image.fromarray(score_matrix).resize((512, 512)))\n",
    "    path = \"./neigh_score_matrix/score_matrix_\" + str(i) + \".jpg\"\n",
    "    plt.imsave(path, score_matrix, cmap='gray')\n",
    "    return path\n",
    "\n",
    "def save_trajectory(phase1, i):\n",
    "    trajectory = get_best_trajectory(phase1)\n",
    "    env = phase1.env.copy()\n",
    "    env[trajectory] = EXIT_MAP_VALUE\n",
    "    env = np.array(Image.fromarray(env).resize((512, 512)))\n",
    "    plt.imsave(\"./trajectory/trajectory_\" + str(i) + \".jpg\",\n",
    "               env, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad483efabfca481f8d2ff1fc5e513778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x08\\x06\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d820e5fc1594a64b8574be8b994cbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-86d4fd35e31d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtrajectory_widget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marr2bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_best_trajectory_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mphase1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell_cumulative_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-f12523fe0aed>\u001b[0m in \u001b[0;36mexplore\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;31m# choose an action randomly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mchoice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CORRIDOR_SHAPE = (21, 11) ## needs to be odd\n",
    "\n",
    "phase1 = Phase1(CORRIDOR_SHAPE)\n",
    "\n",
    "N_STEPS = 5000\n",
    "SAVE_EVERY = 1\n",
    "REFRESH_EVERY = 10\n",
    "# The cell scores and the best trajectory found are saved during the run. The results are found in the folders\n",
    "# \"score_matrix\" and \"trajectory\"\n",
    "\n",
    "# Widgets for dynamically vizualising the state of phase 1\n",
    "neighscore_widget = widgets.Image(\n",
    "    value=arr2bytes(np.array(Image.fromarray(get_neighbor_score_matrix(phase1)).resize((512,512)))),\n",
    "    format='jpg',\n",
    "    width=256,\n",
    "    height=256,\n",
    ")\n",
    "\n",
    "trajectory_widget = widgets.Image(\n",
    "    value=arr2bytes(np.array(Image.fromarray(get_best_trajectory_matrix(phase1)).resize((512,512)))),\n",
    "    format='jpg',\n",
    "    width=256,\n",
    "    height=256,\n",
    ")\n",
    "\n",
    "\n",
    "display(widgets.HBox([neighscore_widget, trajectory_widget]))\n",
    "\n",
    "## Exploration loop\n",
    "best_scores = []\n",
    "for i in tqdm_notebook(range(N_STEPS)):\n",
    "    if i % SAVE_EVERY == 0:\n",
    "        save_path = save_score_matrix(phase1, i)\n",
    "        save_trajectory(phase1, i)\n",
    "        \n",
    "    if i % REFRESH_EVERY == 0:\n",
    "        neighscore_widget.value=arr2bytes((np.array(Image.fromarray(get_score_matrix(phase1)).resize((256,256)))))\n",
    "        trajectory_widget.value=arr2bytes((np.array(Image.fromarray(get_best_trajectory_matrix(phase1)).resize((256,256)))))\n",
    "    \n",
    "    phase1.explore()\n",
    "    \n",
    "    best_score = max(phase1.cell_cumulative_scores.values())\n",
    "    best_scores.append(best_score)\n",
    "    \n",
    "\n",
    "# Finding the trajectory that solves the game\n",
    "max_score = -1\n",
    "cell = next(iter(phase1.cell_cumulative_scores.keys()))\n",
    "for key, value in phase1.cell_cumulative_scores.items():\n",
    "    if value >= max_score and len(phase1.xys[key]) < len(phase1.xys[cell]):\n",
    "        cell = key\n",
    "    elif value > max_score:\n",
    "        max_score = value\n",
    "        cell = key\n",
    "\n",
    "path = phase1.xys[cell]\n",
    "real_trajectory_x = []\n",
    "real_trajectory_y = []\n",
    "\n",
    "for xy in path:\n",
    "    real_trajectory_x.append(xy[0])\n",
    "    real_trajectory_y.append(xy[1])\n",
    "    \n",
    "real_trajectory_x = tuple(real_trajectory_x)\n",
    "real_trajectory_y = tuple(real_trajectory_y)\n",
    "\n",
    "real_trajectory = tuple([real_trajectory_x, real_trajectory_y])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT: Cell scores, RIGHT: Best Trajectory found\n",
    "\n",
    "These are better seen in the saved images as the widgets do not easily support different shades of gray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make GIF of run\n",
    "import imageio\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "path = './'\n",
    "filenames1 = [f for f in glob.glob(path + \"score_matrix/*\", recursive=True)]\n",
    "filenames2 = [f for f in glob.glob(path + \"trajectory/*\", recursive=True)]\n",
    "sort_nicely(filenames1)\n",
    "sort_nicely(filenames2)\n",
    "\n",
    "with imageio.get_writer('run2.gif', mode='I') as writer:\n",
    "    for filename1, filename2 in zip(filenames1, filenames2):\n",
    "        image1 = imageio.imread(filename1)\n",
    "        image2 = imageio.imread(filename2)\n",
    "        writer.append_data(np.concatenate([image1, image2], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = phase1.archive[cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_run.csv\", \"w\") as file:\n",
    "    for i in range(len(best_run)):\n",
    "        string  = str(best_run[i]) + \",\\n\"\n",
    "        file.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Best Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv(\"best_run.csv\", header = None)\n",
    "best_run1 = X.drop([1], axis = 1).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(best_run == best_run1).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate Best Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save frames of the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 43, 44, 45]\n",
    "CORRIDOR_SHAPE = (21, 11) # should be odd numbers for perfect symmetry\n",
    "\n",
    "# Find cell that solves the game\n",
    "max_score = -1\n",
    "cell = next(iter(phase1.cell_cumulative_scores.keys()))\n",
    "for key, value in phase1.cell_cumulative_scores.items():\n",
    "    if value >= max_score and len(phase1.xys[key]) < len(phase1.xys[cell]):\n",
    "        cell = key\n",
    "    elif value > max_score:\n",
    "        max_score = value\n",
    "        cell = key\n",
    "\n",
    "agent_xy = phase1.xys[cell]\n",
    "trajectory_tail = 60\n",
    "alphas = np.linspace(0, 1, 11) ** 2\n",
    "\n",
    "# Save images of the agent's location and state of the game\n",
    "for i in tqdm_notebook(range(len(agent_xy))):\n",
    "    env = create_env(CORRIDOR_SHAPE, SEEDS)\n",
    "    tail = np.array(agent_xy[max(0, i-trajectory_tail):i+1])\n",
    "    tail = (tuple(tail[:,0]), tuple(tail[:,1]))\n",
    "\n",
    "    trajectory = np.array(agent_xy[:i+1])\n",
    "    trajectory = (tuple(trajectory[:,0]), tuple(trajectory[:,1]))\n",
    "\n",
    "    env[trajectory] = 0\n",
    "    env[tail] = EXIT_MAP_VALUE * alphas[-min(trajectory_tail + 1, i+1):]\n",
    "    env = np.array(Image.fromarray(env).resize((512, 512)))\n",
    "    plt.imsave(\"./best_run/trajectory_{}.jpg\".format(i), env, cmap = 'gray')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make GIF from frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "filenames = [f for f in glob.glob(path + \"best_run/*\", recursive=True)]\n",
    "sort_nicely(filenames)\n",
    "\n",
    "\n",
    "with imageio.get_writer('agent_run.gif', mode='I', fps = 60) as writer:\n",
    "    for filename in tqdm_notebook(filenames):\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f for f in glob.glob(\"./experiments/**\", recursive=True)]\n",
    "sort_nicely(filenames)\n",
    "_ = filenames.copy()\n",
    "for file in _:\n",
    "    if len(file) <= 20:\n",
    "        filenames.remove(file)\n",
    "filenames = list(dict.fromkeys(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [\"11_5\", \"21_11\", \"31_21\"]\n",
    "\n",
    "best_runs_score = {}\n",
    "\n",
    "for shape in shapes:\n",
    "    best_runs_score[shape] = []\n",
    "    for filename in tqdm_notebook(filenames):\n",
    "        if shape in filename:\n",
    "            file = open(filename, 'rb')\n",
    "            obj = pickle.load(file)\n",
    "            best_runs_score[shape].append(obj[1])\n",
    "            file.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scores to json\n",
    "import json\n",
    "\n",
    "with open('runs_scores.json', 'w') as fp:\n",
    "    json.dump(best_runs_score, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./experiments/runs_scores.json') as handle:\n",
    "    runs_scores = json.loads(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [\"11_5\", \"21_11\", \"31_21\"]\n",
    "\n",
    "# Normalize scores\n",
    "for shape in shapes:\n",
    "    m = max(max(runs_scores[shape]))\n",
    "    for i,run in enumerate(runs_scores[shape]):\n",
    "        for j,value in enumerate(run):\n",
    "            runs_scores[shape][i][j] = value / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFzCAYAAAB2A95GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXxTVdoH8N9J0qR7S9mhloKAimxKQUVcRhRccVfcQRRnHB1xG9BhBnFFBxVl3Bj3beRFHAdFRUVQVBSKG8iiiFDKvqb7kuS8f9zmJje5SW7S3KRNf18//fQu5977tGD7cM65zxFSShARERFRYlmSHQARERFRW8QkjIiIiCgJmIQRERERJQGTMCIiIqIkYBJGRERElARMwoiIiIiSwJbsAKLVoUMHWVxcnOwwiIiIiCJatWrVXillR71zrS4JKy4uRmlpabLDICIiIopICLEl1DkORxIRERElAZMwIiIioiRgEkZERESUBEzCiIiIiJKASRgRERFREjAJIyIiIkoCJmFEREREScAkjIiIiCgJmIQRERERJYFpSZgQ4kUhxG4hxJoQ54UQ4kkhxEYhxE9CiKPNioWIiIiopTGzJ+xlAKeHOX8GgD5NHxMBPGNiLEREREQtimlrR0opvxBCFIdpci6AV6WUEsA3Qoh8IURXKeUOs2KKyo03As+YnxeuRhHOwBLsQj5cyDb9eURkkuPvAQb+X7KjMNF+oJ0zxDlPQiMhiptaQD4mk/b4ZC7g3R3AVr/98qZjQUmYEGIilN4yFBUVJSS4RCRgAHAM1qCWyRdR6zfyIUAkOwgiikqSZ8YnMwnT+3Glm45KKecAmAMAJSUlyUtZTdAAe9OW8mXZUK2ecyETyrepvumIHcrfGO+3oB7hOQy2I6KwbisCsvdGbicBbD7O9HCaLa0WyDyAED9y9bUrUz43pgWcaFR+NHkAuAJOeQDNj3qHzvNEdGG0Ofzxba6a5D4+mUlYOYBD/PYLAWxPUiyRSXN+SkgrND+oGmWOek4I76MzNPvett7joQReTxRPg58ZjNW7Vyc7jLjwxHE4zXboysjPk564PjOhHI36x61NH0Ei/+y0WZL5q6jl6pHXAxtv2ZjsMMhEyfybvwDATUKItwAcA8DZYuaDmWjKFODll337nmb8HO7SpdnhEMXsx90/JjuEFsklA7uDKBQ5jV1g1LaZloQJIf4D4GQAHYQQ5QCmAUgDACnlswA+AHAmgI1QOgTHmxVLs4n4TfR4+OG43Qq7dsXvXkSxSoVfpGJ6U+9ynL8W733jrUduD2y+dXPM1y/8ZSF+3vMz/nr8Xw1fE6/v0ZrdazDgmQHItGU26z5EqcDMtyMvi3BeAvizWc+PK0v8Z+717evbHjECePHF6O9htQKHHhq+zdSp0d+XiMxnhRWdszpHfZ3dZscnYz8x1PZg3UH8d91/0ehpDDpuFbpjh2GJZrx5cNjsw/DL/l/Ufasl+ucTpRoOxBthjf8Piw0btPuxJGEdOgTfh8hMZ792NpZsWZK05/d/uj9+3/97XO9Z4/bNzM19MDeu9/Z3dJejseqGVSHP/7b/N+yr3WfoXvvd+7Fi24qI7XZU7sAW5xYU5xcjzeKbUJ+VloXi/GJDz/LXnLlbmw5sUrcFBMb0HhPzvYhSBZMwI2zmfJvKyoCTTgLq/d5+SU/X7gOhR0NNCotI14btG7Bw00LNsXx7vinPqmmo0Z24/vOen015nldlY6Vp966pq8GHGz7UPSchMW/tPLilO+7PtVvtOKbrMUizat9qrG2oxacbPzV0j51VOwEoLxQYvQYArMIKS9NIgkcqf56pMHxNFC9CmvTWn1lKSkpkaWmp+Q/yz3yysoCqqrjeVkogLw+oqIj9XkVFwJYtcQmLKKyZy2bizs/uVPdnj56NdFs6riu5Lu7Pev3H1/H898/rnvt8y+cAgN7tekd937IDZWhAQ8jz7eztcHzR8VHf11nvxLKty6K+rq1iEkZtjRBilZSyRO8c+1KMMGE4EgDq6pTPBQXA/v3acxaL781J/21ASeSkNGWqGpGuhb/4esAuPPxC3HTsTaY9a2vFVliFFZcceUnQOW8SdsfwO6K6558X/hluKL1MAgIWof2fx26147EzHkPf9n31Lg9r3pp5ahLmsDo05+rdqVfkKZoJ9RZhgfD7B21JV93fQ0RtFpMwI0wa93M3jTz8/e/Arbf6kivvOSGUD+82oJzv0kV5M9Ju178vUSwGPzMYe2v0C5LuqvK9ivtN+TcofLTQtDic9U7Uu+qxYW/oCY/3fX5fVPf0JmAAsOL6FSjpFr9kYMG6BQCAfEc+Dkw5oDln1tuRyeCwOlA3tS7ZYRClFCZhRqSnm3JbbxJ2SFPJWv+RYW+CJSVQ6Pf7rrAQ2LNH24aoua6Yd4Xhul/bqraZHE3k58QSQ3ZaNirvjv+crwO1SuLlP/EdAKoCpjBc2PdCvH3Z23F/PhG1XkzCjDA52+ms85Z6o98b5du26W8XF5sWErURRY8XYWuFbwlXCywRK7nnppn3BiGgTFK3CRuO7Hik5ni9ux4rd0auRh9KVWOVqT1Te2r3hL1/ut2cf8wRUevFJMwIk3rCjCgq8uWAG5tWr+jdG+jWDXjvvaSFRQly1+K7sL1CfzWvbrndkJWW1az7b6vQ9igd2/VYfL3ja922AgLXD7ke3XO6N+uZRgzqPAjnHn6u5ti/vvmXmoQ1p15VKNHeM5plh9IsaXh29LPRhkREKY5JmBFpgQvWxleoyvdWq/btR++8sF9/NTUcijO3241vtn0T9STtA7UH8J/V/1Fe8xfBb2F0zemKDFvz1gX1JhJDC4ZiS+0WfL/re/WckbfYtldux8R3J6LOE9+5Ql9s/gKzv52tOfbV5q/U7VOKT4nr8wClF9Bui9zrXeeqwxdbvlBLLui5ov8VeP3C1+MZHhGlICZhRjRzOHLKFODNN7XHiop82xMn6l/n//bj/PnNCoGS6OnSp/Ho8kdjvv6O4+7An4b9KY4R+djutcEt3VhXuQ5Vjb45TJOGTjJ0fa8neiXlDcDFmxcn/Jnh6E3KJyKKhEmYEc18O1Jvvcitvmk4QeUpvPzLUlx0kfKZZSlaDrfbjXPnnotd1eEX8axuqAYA3H7c7bCJ6P4uZaRl4PKBl8ccYyTeOoG1rloAQKfMTuia3RWPn/m4bvv0+9N1k64umeasJr+zZqfucTOeJyBgs0b+89laqfzPa4UVuSIX7fLaYf6l/FcSEUWPSZgRcZoTVlwMbN6sv223A7/8om2fr1OM/PPP4xIKhbCifAX+u+G/htrWu+qxZvcadMjsgA6ZHUK2a5/RHofkHoKbj7k5XmHGRWVlpToc6a3UvuvO8AmlXgLmsDqw484dcYnpmvnXYO66uSGf5XWgPv69ThZYICzG54W5prniHgMRtS1MwvQ4ndr9ONUJ+/1337yuwG0geHmiTJ2aiCNGxCUUCuG+Zfdh9a7VhtsLCEw6dhKuHHiliVGZ4/x3zo/52liqnpduL8UP23/QPbd+x3rsqtuF19cam0dl2hBo/FcNIiIKiUmYntUBv4Qf1x+aMSIwnwvVZtCg4OPl5UCPHjE/mmJQ56pDh8wOeP/y9w21t1vtKMgoMDkqc2yvVN667JXXC5ucmyK0Bo6YfUTMz/pww4c4860zY77e301DbsKxhxwbl3sFsluNzf88ofgEU55PRG0LkzA91dXa/QEDYr7VyJG+7UWL9Nuceab+GpBSKot8U+K43W7YLXZ0yTZnjlNLsm7fOgDKcKmRJGz9/vUAgKFdhkb9LP8ELNqlffzbt09vj9lnzw7Tmoio9WASZrLtTSWeunYF1im/82CxaHvItuuUgbLZlFpg/saPNyfGtmrp70uxbs86zbGD9QeRbc9OUkTmq6ysxJCXhmD7Ad9furU716rbXf/ZVfe6PTV71O3Nzs0h2+mpc/nKV6Rb05Hv0E523FO7B27pxtGdj8Z3u77TnLPAwqVyiChlMQnTE7DcSHPUN/0jv1Mn34LdVqtvxNNi8S1f5M+/Yj6Z448L/6hJELy65XTTaZ0aLnv3Mvx6QFtorhq+nt9QbyP621O7J2KbUOrcdSGfcUzhMWoSFsucMyKi1oZJmMm8+Vxeni8Ja2wEzm+aEy0EcIDlhRLqhx0/4LJ3LkOdqw4n9TgJ4wdruxiP6nJUkiIzX3lVedCxUw45BZ9t/QwAMLrnaM25zzd/jjpZp2mbZgtfvHjR7/rj7uGu7VXQC0+f/TSeWfVM2HsTEaUSJmEma2hQPh91lC8JA4C9e5XPdntcO97IgB92/oDaxloM6ToEdx5/J/p36p/skOJq2HPDULqzVPecRHAPkzcBA4CPf/84bPslW5cYjsMCX1G7fEc+Fl+rX2D1X9/8C7csugXPruKyPkTUtjAJ01NTE/dbzpoFTAooQt67N7B4cfAbkFyY21wb9m8AANxyzC0tNgEbO3csNh0MP1nearXC1vS/8J6aPSivUHq5qt3V4S4LSy9Ji+a8l81iQ+PfjY2p3/P5PZp1GG0W/lgioraBP+0SqD7gJbBQa0AGTsin+KltqMV/Vv8HAFrsG5AT3p2AuevnJjsMDTPnaDW6lWTt+sHXY865c0x7DhFRS8MkTE9trSm39Q5NevXsqd+uoHWWnWoVZn07CwBQ0q0EfTv0Teizcx/IRaWr0nB7q7CGrcSfJtKApgK/5ZXauV7ZtmzkZ+QHHfdXmFMIADhYexBVrirNMX+DOuoUsYsjb7X+LlktMykmIjILk7AECuwJ8y5bFOjQQ00Ppc1au0cpx3DPyfck/NnRJGAA8M5F72BMvzGG2orpSjZW4ChAVWMVGjwN2F29O+w1W2/bipnLZmLKkikAgDx7HrbetjXsNfF26iunotqlDJ8W5RdFaE1ElFqYhCWQy2+puexs5Y1JANi2TdtuwoTExdTWNHoakWHLSPhcsIqKCnU7HkN7lZWVeO6H54KO768PsRq8jg3bN2DKkilqT1RhXnAvmNkWb/ZN1j+hG6vQE1HbwiRMjwkT8wFtT1ilX6dIVpb2kUXsEDCNW7ohAhfpTIB2j7eL6/3yHssLOUm+Y0ZHvHLuK+r+mP8bA5fHhdfPex0F6cpY96Bug9D9se5qm5XXr0RJt5K4xhiNbbdtS+n6bEREepiEmch/CcqRI4Gvv/bt9+mjrA3Z0AB4PNrrvD1kFH8ejwdWYU38c5ve/ju1x6lxuZ83AbMJG1zS18Wam5aLD678ACXdSnDqK6dqepquGHSF7r2O7HhkQhMwx30ONHi0EySZgBFRW8QkTE9dfJZJGTLEt/3ZZ9pzGzfG5REUpWT1hHl9Mu6T+N5QAN4OsQJHAfZN2aee+rzsc79mob/mNTeuiW9MfiorK3Hk80eipsHX1RuYgOXb8wMvIyJqE5iEmci7HFHnzsCuXdpzmZn6o57sBTOXW7phtSS+J8wsLo/SCzZ79GzcdOxNmnNSKtlZuDlo4ZKzeDhz7pnYWhE82d9hdXBNSCJq85iEmajpdyDS04PPXX898MQTSsX8+nqgXTvg4EHgyCMTG2NbcNfiuzDv53mQUsIjPWif2T7ZIYU0+aPJeOTbR6K+7uZFN+PmRTfrnvO+OalHQoY9Hy/dsrphaLehAACb1YaXznzJ9GcSEbV0TML0xGk40mv79uBj3on53pExb8Jm459I3H2x+QvYLDYcf8jxAIATilrWW3gVFRVo93g7TdX4RPJfXsgMNosN629Yj5ycHFOfQ0TU2vBXvp5QBbxi1Kizekt108oylqbff0zCzGOz2GARFrxw7gsJe+ba8rUY/dZo7KrWjkMPeGpAUNsNezc0KwELnAvmVVlZiYJZBeqQZSAOCRIRJRd/5et55ZXIbQyQYcpBeZMwb0+Y9w1JJmHx55ZudMzsmNBnDn5pMBo9wdn3mr3NnwQvIDTlKTb/ebNuO29pCgC4/6T78beT/9bsZxMRUfzwV36CFBQA+/3qaHon5Qf2hNntiY2rLfB4PLDbzP3GWqZbDC9uHUn37O4hz1lgwV3H3IUbF98IALjw8AuDhvls99rUAqyAUgmfCRgRUcvDJCySOJUzCLzNihXKZ2vTi3p6Q5YUH264YbGYO+8pXgnYofmHYuMt+vVLrpl/Dd74+Q3ctFh5C9JhceDtS99Wz3ef2R17avdoEjABgbU3rY1LbEREFF9MwhIkcJixSlkvGZmZymfv4t5cNzL+PNIDmyX2v+oPLn0Qzjqn5lhFRQVK95Yaur6kYwlK9yht/3rMXyO2n/zRZN3jr655VbMfuLj39mrfGyBpljQ0/D1gxXgiImpRmIQliF5HTFERsGyZ9tisWYmJpy3xyNir5Oc9mIeKxorIDcPwJmAAYio/EejnCT8DAI7ofkTQOQssWHv9WhzW7bBmP4eIiMzFJCxB9JKwLVsSH0dbUNVQhcvmX4bKeqUOiLPOGdOyOJ0e6aQmYOnWdLXSfq2rNubYMmwZMV8LAIM7Dka/wn4hzwshmIAREbUSTMJMMmeOdt+aOkXaW7zSbaVYvWs12mW0Q6YtE52zOmNUr1Eh2y/+dTEunn9xUCmHykbfKutpljR1O8OWETERExDwTEtc3a9K/xXhiYioVWASZpIbbtDumzwvnPxUNSoT7m4ZdgvGHTUuYvvz552vSbj06J23wgo33EHHj+t6HL6e+HXQcTNtr1TmgyVzXUwiIooOkzCTpaUpbz4GTsy/4orkxJPKVm1fhcvmX4ZGt/KqaV66sYU4G9zKBPZBHQehd7ve+HnPz1h/YL16/sK+FwZd0ymrE0p3lGLlzpWa45cefineuvStWL+EmO2s3QnA/Or3REQUP0zCTJaXB+zdC7hc2mOvv568mFLVxn0b0eBuwOAug9GrXS+cfujphq7zVqu/5dhbMP7o8Rjy7BD13BHtj8Dbl72te51e9fs5Z8zRaWm+GpdSeI49YURErQeTMJMdOKB89l8JKXBocvXqhIWT0rxDg9cMugbnH3F+yHYPLn0QL69+Wd33VrZ3N7jR71/9sOnAJgBAr7xeujW2Fv+6GDcvuhnr9q0LOpebm9ucLyFqM5fNxMurX0ZFffPe4CQiosRjEhZJM3sW3MFThtC+vXZ/4MBmPYKauNxKd2OkchR/+1y/evz1i67X7PfK76XbbtSbo5K22HagOz+7U7PvsDiSFAkREUWLSZjJ2rcH9gWsrRxqkv60aebHk8o8UkmMjFbHL84tVreHdBmCd355BxISxbnF6JjZEZ+M+0TT3jrdGjH5EtOTMxzYp10f2G12zD9vflKeT0RE0WMSZrK9e4M700KVq7jnHtPDSWne5XosQknCnv72adyy6BZISM1SPl5bK7dqtr1LD22t3IqtlVthu9f3v4fe9S3F0C5DseKGFckOg4iIosQkLI7KyoBRo7RFWEtKgttVVQGjRwf3kFHzeHvC6mrqcOOCG/HvH/4Nl3SFbB8qsYo24bql5BbMOotLHRARUXSYhMVR797BC3GvWhXcbscOYOvW4OPUPN4k7KJ3L9IsqP3uxe/ivHnnAQC2TlC+8YET6PMe95WzcN6qXSey6PEiOOFEZ1tn7HbthoREUXYRyqrKAIAJGBERxYRJWBy5dDpdCgqA/fu1x6xWpW1aGpCToxw74wzz40t1Ho+ShHkTsCxbFrpkd8EF8y4AoFS9/67iO5w779yw9/FPyPz16dIHu8t3AwC+uv4rHPL4IfEKnYiI2iBWdowjKbX7QugPOXrbnXWWcn7fPtYNi4fA6vWPnPoIdlftVifT9+/YP2ICFs49J96jJniFuYWxB0pERAT2hMVswgRgzZrYrvUOWXbpEr94CJBSqr1hAPCXRX9R53dZhRVbndox4C5ZXbDjjh0JjZGIiMjL1CRMCHE6gCcAWAE8L6WcEXC+CMArAPKb2kyRUn5gZkxR6xVcK2rKFODFFyNfGqpSgrcn7KijmhEXBblj0R1okMoSRAICsukbfe2ga/H4KY+j++zuats8ex4TMCIiSirThiOFEFYATwE4A0A/AJcJIfoFNJsK4P+klEcBGAvgabPiidmvvwYdWum3XGC7dtoPf3Pn6t8yLQ044ghg4sQ4xtnGVVRUqAkYAFzV/yp16PCF815Abm6u5k3J4rziqO9vnR6+CCwREVE0zOwJGwZgo5RyEwAIId4CcC4A/3VgJADva2p5ALabGE/c1NUpn/Pygifd+9cEuzB43WcAwAUXAG8lfo3nlLFg7QLc+vGtmmN7a/aq26XXl2JItyF4bc1rAJQEqssTXVDnqVPbXD3o6rDPGD5nOHbV7FL3KxsqW0yVfCIiSg1mJmHdAfhPwikHcExAm3sAfCyEuBlAFoBTTYwnburrlc8Wi1Ib7KqrlLcdnc7w11F8nDfvPE0JCn9WYUV+ej4A31uSvZ7uhVpPrabdbcffFvL+F/3nIizfsVz3XOeszth5x85YwiYiItIwMwnTW78l8DfnZQBellI+KoQ4DsBrQoj+UkpNl4MQYiKAiQBQVFRkSrDR8E/CevXSXx8yHBtfh2gWb3LVp6CP5vje6r3Itmfj0IJDNcf31fteUc2yZWH2GbPD3n/D/g0AlJIWxfnF6vGctBwsuXxJc0InIiJSmZkOlAPwL6RUiODhxgkATgcAKeVyIUQ6gA4Advs3klLOATAHAEpKSvS7QBKooWnqkc0GeF/Gy88HDh5UtjMygBNOCH29g2ssx8UvN/+i2b943sX4effPAICcB3KC2s88ZSZuP+H2iPetaawBABTlFgU9AwDGzh2LeevnxRIyERGRyswkbCWAPkKIngC2QZl4f3lAmzIAIwG8LIQ4AkA6gD0mxhQX/kmY903HAwd888FqasJfb7ebF1tb5vF4YBVWLFi7AFWuqqDz4RKwyR9Nxhanst6Ut5TFrspdGDt3bFDbuet9b1wI3Q5fIiKiyExLwqSULiHETQAWQSk/8aKU8mchxL0ASqWUCwDcDuDfQohboQxVjpMysORpy1NRoXz2X4j7nHP02+otys2esNj1fqJ3yHNu6YZFWHDpO5cCALJt2QCgm5D5G/bcMKzcuTLoeJW7SpNwBZLTWvxfVSIiasFMnZ3UVPPrg4Bj//DbXgvgeDNjMIP3jch27ZSJ+QDw/vvB7crKgOnTg4+np5sXW6rKeSBHk0wV5xYHtXF5XLBYLGj0KNVw/332vzFuwbiI9/YmYGmWNKRb01HZWAkAsMCCrLQs3WuO6Rb4jgkREVF0OEW8GT7/XJkL5mW3A3/6k29/ZXDnCgAmYdFYW74Wx756bFBv1q7qXch8IBOAknx5Ey9/175/Leo99eq+t30oP4z/Af0K+0FMV4YYV09YjX6FgaXtiIiI4oNJWDPkBazzfPHFwKxZvn2dOq8AmIT5K68oR4V3fFfHSW+cpPZM+at11+q0Dmjjqg277y/PnheUcDEBIyIiMzEJa4bAumA5AS/kMQkL76XvXsK1711rqO3JRSfj87LPQ9YH8zqy3ZGwCGVIcv3B9erxNKThxpIbda/plNUJd598t/HAiYiI4oBJWDMUF2v3Ayfch1pfMjP8qFib8eZPb6rbVqFdEsi78LbX0rKlEe93dOejseqPqwAAuQ/kas69ffHbGNNvTIyREhERxR+TsGaortbu+88PCycjI/6xtEabDm4CAHTJ6oIdd+zAsOeGYf3O9ahE8PCjvxzkoFdn38Lqdqsdr5//Ovp26Kseq3Rp78EEjIiIWhomYc3gLdRqsSjbRocZ2ROm2ORUkrCeuT0x4d0JumUi9JTfWo7c3NzIDQEcnX80Vt2yKuYYiYiIzMIkrBm8yxV5i7QWFCQvltZs+Y7lQWs1OoQDvfJ7wdpUjG3TgU1wuV2YcNQEwwkYACZgRETUYjEJiyOjw4ydO5sbR0s24KkB+HnvzxHbXTX4Ks2+xWKBw+bA02OeNis0nPHqGVj0+yIArIRPRETmYxLWTP37A+vWKdv+w4z+b07m5vqq7APAiBGJia2lWbB2AdbsXROxXaYtE59s+iRosv7hHQ4Pec3a8rWY/PnkZsX30e8fqdveavtERERmYRLWTKtX+5Yv8u/h8lbSB5SETLBjBefOO1fd9i754y2MaoMNr1zwCu5erJSK6JTVCSuuX2H43ke+cGTc4uRyRERElAhMwuLAO0F/61agd29g3z6gvj78NW2ZFVY1+fKy2+zqwtlXDLgC5/QNsRhnBHl2pYKus8EZoaXWjQv0a4gRERGZhUlYHF1+ebIjaLn8q+K74Q46f3qv0/Hl1i8BANcdfR16tusZ03MO3nUQAIKSvEBDnh2CtXvXqvt17jrlOs4FIyKiBGES1gzDh0duc/LJpofRKgx+YXDIc4dkHYJVu5S3GB1WBzpmdYz788sryrFh1wZ1/7td3+m2e/fid+P+bCIiIj1Mwprhq6/0j1utgMuV2Fhauv21+9Xt0cWjsWjzIliFFQ/+4UHM+X4OXB4XLul3Cf52wt+QbY9uUvza8rURz4eaM/b3EX9Xt0u6lrCoKxERJQyTMBNYLNr9wDUm26IGT4O6XVGvDE3arXYc1e0ouFa50D2nO24bfhvyMvJC3SKkpduWhj0/au4oddsmlL/yQghcN+g63Dvy3qifR0REFA9MwqLUr1/kNoFvQgauMdlW9HmiDw7UHwAA1Lpr1ePr9ysLa2fZslDVUAUAuPjIi9Elu0tMz9lyYAsAIMMWXKhtyLNDsK1qGwDg9J6n48OrP4zpGURERPHGJCxK5eXRX1NT49u+9tr4xdKSjXxpJDYe3Bh03AorXB5lrPakopPgkcqrpZ2yOsX8rC1OJQmz6fx19p/7xQSMiIhaEiZhUfKWo/DyH2q89lrgxRfD1wR74QVz4mpJ+s3uh3X7lQq26dZ0ZFmzsK9hHwCgQ1YHdTiyU1YnuNxKQpZmSQu6T6Q3HAPZrPp/na3CiruPvzuqexEREZnNErkJ+XP7VVdwOoFx43z71dXK58A5YbKN1f787eBv6vaKq1egINu3qOas02ah1qUMTRbmFqJRNgIAbJbm/XtAQOD+P9wPQFsOAwBy7bmc+0VERC0Oe8Ki5J9QFRYCVVW+/XfeUT4HJmGBvWepzi2VTPXVc17FgKIBaHQpiVafgmFdD+cAACAASURBVD4YO2gsLnv3MgDAeb3PQ+neUgAIWqLIn14F+2vmX4OyijLNsXlr52He2nn4uuxrzfHmJnhERERm4G+nZqit1e57k6377098LC2JbMpUB3dQaoM1epQkLNOaqWnXr7Aflu9eDiD0UKJe8dTBTw/Gj3t+NBxPriPXcFsiIqJE4XBklNzBxd4BABkZvl6yCy5IXDwtjdPphAdKNjqgaAAAXxJmt9qD2nsn5vv3hL3141u688EmfzQZYrpQEzCHxYGC9ALNh798ez66Z3fH0vFLm/+FERERxRl7wqJQVhY6CbNafT1hTicwdqzvXKhrUlGZsyzo2L4aZVJ+lj0r6Jw6Md/qm5h/1f+uUreP6nyUuv1k6ZOaazfeshGFuYWaY4WPFmJb1TYU5xbj91t/j+ErICIiSgwmYVHo0cNYu4EDzY2jJXNCeV3UCl/PlnetyNN6nhbU3nvO4tcp65JKYnbtoGvxwnm+10m96zu+eM6LGH/0eN3n763ZCwDomBn/pY+IiIjiicORMUpL007SP/TQ4DaZmcqH14knmh9Xsu2q2KVs6FSXuPvk4DIRn/z2CQAgMy0z6Jx/AnbRfy5St0MlYABQ76kHADx51pMh2xAREbUETMLipH374GPV1cqH923JBQsSG1My7Kvdp9lPvz9d3T7t5dOC5npZhPLNGdJ1SNj7LvxtIQD9emJeGff7KuYfW3issYCJiIiShElYnGQGd+QAAO65p22VqPAu1G2BBfPXzEe9u1499+mWT9VtbzK1p2YPCjIKYLWGLlEBQK2yP+OUGSHbeIcrwyVqRERELQXnhMVICO1wZFbwnHOMHAl89plvPy/6talbnYN1BwEoC2RfOv9S3Tb+db+cdU61N8xfYGkK71uU1w24LmIMDX9viNiGiIgo2ZiExUm7dsHHNvotndhWFvGua1R6o4QQaqkKADi267GwWW0449Az1GMf/PoBKhsqscW5JWiY0j8Je+yrx9R75eay5hcREaUGJmFxotfL5e0pKyoCfk/hagkjXxqJz8o+0xwTEJDw9Xgtn7hc3b7v8/vwy75f8Mlvn2BXzS7NNV7n9z1f3f7r4r9q7l30aBG2Vm3VjUWvuCsREVFLxCTMoBkBU5EaAka88vMTF0tLE5iAAUDPvJ7qIt5ebrcb32z7Bi9+/yIswqJJwADg+MLj4W4qqra9cjsKZxZif+1+dRmkLhldMHzO8JAJGADkpOU098shIiJKCCZhBpxzDvD+++Hb9OkTfMw7IT9wLclUFbjGY+AQ48JfF+IvH/0FAHDd0dfh7s/uVq9Lvy8dX5Z/Gfb+O2t3YmftzpDPIyIiak3aSHrQPD/95Nvu2lW/zYUXBh/zJmE2proAgH9//28AwJ9K/oSbj7lZPf5N+Tdqfa9OmZ3UD3+ZtkzNuUdPfTRxgRMREZmA6YEB9U1VFvr2BUaMAF580dh1ba0nLJLNBzYDAG497lbNOpKzvpqlbu+602+O2HQBAQHPtDZU44OIiNoMJmEGeOd/5eT4ErJATmfi4mltvItzVzdWAxL41zf/0pwv3VkKAOiQ3kE9VlFRAYAT7YmIKHUxCTPgwAHlc9eugMul36agIPiYd+HuCHVIU97ScUsBAL8fVF4Rvf3T2zXnfzv4GwAg1+ErP9H5yc4AoFtDjIiIKBXwN1w4Qvh/wuuvh27qXxXf4QCuuMJXoqKtJ2ED8gagcGahuu+wODQLfDssDmTZsvDeRe+px7zV7x8e+XDiAiUiIkog9oRFIS8v9HCkvzolf1DXk2xLSdhJL5yEH3f/qDn2SOkj2Fa9DQCQnZaNT67+BCNeHAFIZbix7u91mvaTP5qsbt92/G3mB01ERJQETMIorr4o/yLo2FMrn1K3V01chZI5JWrtrzuPuTOo/SPfPgKAa0ASEVFqYxIWpQ0bjLf1DkemYomKwBpgoY4BgLPe99ZC3w591aHGk4tOxsOn+4Ybsx/IRrWrWt3fe8veeIVLRETU4qRgemCu2lrjbVN1TpjjPkfU1wgI9MjtgQnvTkCjpxEA8NBpD6nnM+7PUJMzAYHD2x/OdSKJiCilMQmLUqQ5YcKvMygVe8KcTicaPA2RG/r5+IqPcVrv0wAA9vt89cH65fYDACz+dbGagAFgXTAiImoT+HakAdJvdZwdO5IXR0vwzc5v1G1v/S8AsDT9VVo2fhnkNAk5TeKmoTchz5GHDHuG2k42fTM/vfxTtafrtDeVBC3DlsGliIiIqM1IoT4aE4joC4Wmck9Yj8d6oKyyTN23Cqs6wd7r7sV3Y9OBTQCABrfSY5Zr9w0rSijflFPfPDXo/qXXlMY9ZiIiopYqRdKDxLPbgSuvDF7C6IEHfNuptnakfwIG+Hq1AMAD5Ytdu2ctHFYHdlXvUhO0Qc8NghVWCCGCkjavDFsG+hX2MylyIiKilidF0oPE8F+ayDs3LDAJmzLFt51qPWFeQzoNwardq5BuS0djY6PmXHVDNbq264rtVds1x91wAzojjRx+JCKitirF0gNzGVkf0j8J8+Yndrt+29aqsrFS89mrPdpjn3sf1uxdAwCwwoqFYxcCAIQQsAorTnvzNEhIfHr5pxjaeWhiAyciImpBmISFEzAnrEw7Goc//Sn4kod1VtnJy4tjTEnS8ZGO6natS79OR62tFnApk/TTrGl4cvSTGH3YaN22I/uMNCVOIiKi1oJJWBR27dLuf/llcJvAXq+MjPBrTrYWe2uVwqlpIg1VDVW6bWpcNQCAm0tuxqyzZiUsNiIiotaIJSqisG+fdr9KJxepr9d+HDyYmNgSpeEfDSF7wrzO6H1GgqIhIiJqvdgTFoX587X7RhbzTjWhliYa1XMUAOAPxX8IOQQJ+EpUEBERtXWmJmFCiNMBPAHACuB5KeUMnTaXALgHyrtzP0opLzczpqgEzAn7+GPt6cDhyVQ0Z+Uc3PDBDRHbLbp6Udjz/ssSERERkYlJmBDCCuApAKcBKAewUgixQEq51q9NHwB3ATheSnlACNHJrHjiwWoF3H5lrmKo5drq3L3k7ohtHNbIa0n6J2A2wQ5YIiIiM+eEDQOwUUq5SUrZAOAtAOcGtLkewFNSygMAIKXcbWI8zbZ0qfLZm3x52sAShy63K+hY+4z2mn0rwq9QXlFRAUB5a1JOk2j8R2PY9kRERG2BmUlYdwBb/fbLm4756wugrxDiKyHEN03Dl0GEEBOFEKVCiNI9e/aYFK4+/9pg773njUf5LNvA9KZGT3DCdKD2gGbfZgnfszV/ozKZziL4HggREZGXmeNCeoN1gWmLDUAfACcDKASwTAjRX0qpeadQSjkHwBwAKCkpMTf1CajImp/v237kEeVzKg5Dzvp6Fu745I6gifPe5YjCHctx5AS1mfHFDExdMhUSUm0vUvEbR0REFCMzk7ByAIf47RcC2K7T5hspZSOA34UQG6AkZStNjMs4naTBbgemT9evnt/alif6suxLvLTqJQDAKz+9oiwtFIM7jrsj6NjUpVOD7nfSISfFdH8iIqJUZGbasBJAHyFETwDbAIwFEPjm47sALgPwshCiA5ThyU0mxhRZhLWJvGUpAqvnA8Dw4SbEY6ITXjoh6Niy8ctQlFekOdZjVo+gdgM7DMSOmh34deKvyNNZEsC7ULf//QLvS0RE1JYZSsKEEB2hTKIv9r9GSnltqGuklC4hxE0AFkEpUfGilPJnIcS9AEqllAuazo0SQqwF4AZwp5RyX6h7JlyY4TO9JKwl9IQd9uRh+OXAL1Fd4327sXNmZ4woGqEet0y36Nb16tuuLxx2B9Lq0nQTsDKn75vjfz8iIiLyMZo2/A/AMgCfAsbHrKSUHwD4IODYP/y2JYDbmj5alerq4GMtIQmLNgHrnt0d5beX654LVVh1w182oO+TffVn/QF46POHooqBiIioLTKaNmRKKSebGklLEWE40ktvyaLAdSOTSU5r3vsLzqbvg4DQTcYaPA1ocDfoXlteoSR1mbbMZsVARESUyowmYe8LIc5s6tkiADU1wceyshIfh7+TXmjexHfrdGvQm48WWHQn7AshUJBeEHR8xhcz8P5v7wMwVsSViIiorTJauOkWKIlYnRCisumjwszAksa/JyzMnLDAxbyB5A9H/rT7JwBK4hSNSQsnQUwXvlISTf9ZYEGOPbj8BAB4PB6k29KDjr/989vq9r/P/ndUcRAREbUlhn5bSylzpJQWKWV603aOlDLX7OCSLkwSVue3DKKl6bvoSHLHT0WDkheP6TMmquue/f5ZddsCCw5MOoCBHQciG9k42HAwqP1TK55Cg7sBNmtw1rl+/3oAylyzC/tfGFUcREREbYnhvhshxBgAJzbtLpVSvm9OSK2DfxKWlqaUrkjmnDCn06n2ZJ1UHN2wpMujLE30+GmPY9LwSeg3ux/W7V8Xsv3fPvsbACA7LTvoXLVLeWOhR15wWQsiIiLyMVqiYgaAoQDeaDp0ixBihJRyimmRJYv/a49DhyrvhOrwT8K8yxfpVGtImCvfu1LdnjR8kuHrxHRfb9+tn9yKWz+5NWz7/h36449D/wgAOLevshToPYvvwfQvp2vafXAxpw8SERGFY7Qn7EwAg6WUHgAQQrwC4HsAqZeE+fvii5BlGDZv9m27m+atpwdPkYqLSQsnYXbp7JAlIwBfOYl2jnaG73vO6+cYbmsTNmTZs/DGhW9gYJeBAJSljm7/5Pagyfyjeo7SrR9GREREPtFMJc8HsL9pO3V/w/rVnujYUb/JjBnA3Lm+fW8S1q1b/MNxOp14ovQJw+1njJxhqN1r372mvsUYyAKLZpK+Z5oHQ+cMRZmzDA9+8aDa7u11b2sSsMnHTcaMUcaeT0RE1NYZTcIeAvC9EGIJlL6hEwHcZVpULURFwPufRU2r7nz4YXDb3Fxg4sT4x9B1dld1u7m1v/xd/d7VusflNAnLdN/7Gp5pSpLl9rixu2Y35q6bG3TNsvHLWBmfiIgoSoaSMCnlf4QQS6HMCxMAJkspd5oZWEsgA3Ken5QKELr1XA3WeI2K0+lErbsWgDIXK5739ZduTYcFFtw87GZk3p8ZNOw5+ZPJ2HTQt6RnhjVD3e6Y2ZEJGBERUQzCJmFCiMOllOuFEEc3HfKub9NNCNFNSvmdueElgV8VVo92qhPy8oBFi4B1oV8cjKsFvy1Qt1f/eXVc7jn61dH4+PePNcdqp9aq2w8vf1jdtsCCmz+4GQt+WaBpXzNVp1ItERERRSVST9htACYCeFTnnARwStwjSrYwXVpdugC7diUulOe/fx4AkCbS4nbPwAQMAFwuFzY5NwUdz3Hk4LWfXgMA9G3fFyu3r4xbHERERG1d2CRMSjmx6fMfEhNOC1BbG/LU/v36x61Wc0L5ovwLAECX7C6m3P/agddiTN8xSHtAP8kr6VaC+/5wHwBgzY41TMKIiIjiyGidsIsBfCSlrBRCTAVwNID7pJTfmxpdMlRWqpuBc8IChycHDQJ+/BHIDq5Z2iyBazguvGhhTPc5/vnj8fW2r0Oef/GnF/HiTy/qnrNb7Hho5EM47vnjNGtHilA1O4iIiCgqRhcZ/HtTAjYCwGgArwB4NsI1rVNgphXm1MGmFX3i2RP22nevaRKw7tndMaBoQEz3CpeARdIxsyPOffPcoMW7LznikpjvSURERD5GS1R4fxOfBeAZKeX/hBD3mBNSkvlNzA/sCQvc37JF+ZyVFb/HT106FYAyD6zhHw3xuzEAG2xwwQWH1YG6qXVo91A73bUhAWBb1TZ1O9Oaieqp1brtiIiIKDZGk7BtQojnAJwK4GEhhAPGe9FalwbjiY/VqnwsjG20UFejuxGAOWsvuqCsEWkTNuQ/lA9ng+8lBAccOCT/kKBr0m3pWHhlHL9AIiIiAmA8CbsEwOkAZkopDwohugK407ywkshvTlgkLlf8H98glSQwK81499qiDYtw5ltnhl3WyN/UE6biriXaWrt/POaPmHX6LOOBEhERUbMYTcK6AlgopawXQpwMYCCAV02LKpn8esIChx8Twd20BpLD5jB8zTULrglavzEUb9X9wCRscJfBhp9HREREzWd0SHE+ALcQojeAFwD0BPCmaVElU2NjUh/v8ijda9lpxl+5rHfVAwCGdR0GOU2qH8vGL1Pb5Nnzwi57NG7wuNgCJiIiopgYTcI8UkoXgAsAzJJS3gqldyz17NmTtEevLluNKpeygHiuI9fwdY0eJXHMT8/XHB/5ykh1+5FTH1G356yc05wwiYiIKA6MJmGNQojLAFwN4P2mY/Er496SuN2R25jkgW8eULfvHXFvxPbz18xHxv0ZqHYpby52zOqoOd/g8Q2tThzqW1182tJpzQ2ViIiImsloEjYewHEAHpBS/i6E6AngdfPCSqKa5K2LWN2gJFOZtkxDtcGufPdK1Lnr1P3RPUfrtgtc9mhPjba3z5KiL7oSERG1ZIZ++0op1wKYDOC7pv3fpZQzzAwsaTYFr6GYKBX1FQCUEhJGuD1Kr90pRafg7QvfxlVHX6XbTghtlXv/AqyTj5uM/ZNCrMdEREREpjGUhAkhzgHwA4CPmvYHCyEWmBlY0lRVGWrW1YQZcd6eMKvFWAl+j1TeiLxx6I24sP+Fhq4ZN3+cZn/GqBnIy8szHiQRERHFhdESFfcAGAZgKQBIKX9oGpJMPQbrUmzfHt/HXjn/Svyw5wcAxpMwb4/W0EOGqsfuWXwPnlr1FPbX+nq3GjwN6PiIMl9sb+1e9Xixvbi5YRMREVGMjCZhLimlM2BYKwlVtBIgGcXBALyx5g11u2NGxzAtgxXlFanb07+crtvGP/ny+v2u36N6DhEREcWP0RnZa4QQlwOwCiH6CCFmA4h9deiWrCkJ+xNmJuyRPWf5OhVPLDwRy69eHrd7F2X6ErQjCo5A+/T2cbs3ERERxc5oEnYzgCMB1EMp0uoEMMmsoFqCL3FyQp7juM+Bzc7NAID+Hfrj8wmfxzxHK/3+9KBj0urr2Vt781rcOPTGmO5NRERE8RVxOFIIYQUwXUp5J4C/mR9Sy+CGsXlZzTF/zXxNLa/Vf14d8Rqn04lL/ncJdu3dpR476YWTUFVfhXp3fVD7rZVbNe02HtjYzKiJiIgoHiImYVJKtxBiSCKCaUkSkYT9uv9XAEodr4Z/NERoreg8u3NQsvVF+ReGrvVvJyDCtCQiIiKzGZ2Y/31TSYp5AKq9B6WU75gSVQvgSUAB0y0HtwAALBbjz2p0B69tmZuWi3p3Peo9wT1h/m0AoLqxGm64cc8J90QXLBEREcWV0SSsAMA+AKf4HZMAUjYJcyWgJ2xn1U4AgFUYf5b0eynVKqxw/UNZ8HvGFzNw15K7gtsHLNp97f+uxTvr3sHZh58dS8hEREQUJ4aSMCnleLMDaclycoDKyubdY/6a+UHHvPOz0izGluFcXbZak4RNPX6qur1l15aw1x6sO4g6Vx0q6pSq/N1yuxl6JhEREZnDUBImhHhS57ATQKmU8n/xDall8B+OdDial4Q57nNoJuAHSrNGTsLmr5mPi+ZfpDmWn5Gvbj+79lnNuUNyDsHCixYCAD7Z+AkumX8JZFP5DSEEOqR3MBw/ERERxZ/R4ch0AIdDmRMGABcC+BnABCHEH6SUKVeuQvolYXuD65wadv6b56sJmN6wo1VY8d+x/414nw9+/SDoWGZaJpxOJ/Jn5Qeds1vsuOoDZS3J6oZqSCkxtNtQdMrqhMM7HA6bzegfPREREZnB6G/i3gBOkVK6AEAI8QyAjwGcBiByXYVWKF4T8xduXKhue+dvxcK7DFGmNRP17nq44Ub7jPZ46NuHdNvvq9+HffX7kGPPAQB0zuqM1y54DV2yu8QcAxEREcWP0SSsO4AsKEOQaNru1lS+IvQrea2YJ04T891SWd9x2fhlzbpPRb0yl8siLOq8sM65nbF57WZNO7vFjgZPAyywINuRjS2Tws8VIyIiouQwmoQ9AuAHIcRSAALAiQAeFEJkAfjUpNiSKl49YR54AAAD8gY06z517joAgM3i+yMryivCx799rGnnHfqsaaxBQUZBs55JRERE5jH6duQLQogPAAyDkoTdLaXc3nT6TrOCS6b9cUjCviz7Ut2OdSmisf83FnPXzVX3DzYcVLd7zOoR8jqHzYGJR0+M6ZlERERkvmgyjaEATgAwAkDKV9D3ILPZ9xj/3+ZV9ihzlmkSMCPmXTwPw7oNg1VYceeIlMyPiYiIUoKhJEwIMQPALQDWNn38RQihPyM8RYQbjjzxRGP3qGxQ6lr0bdc3phh6zeqle1xOkyjOK9Y9d92C67Bh3wbYrfaYnklERESJYXRO2JkABkspPQAghHgFwPcAgku0pwgZJgkzWt1hV42yyHaHzNhqcrmhTOo/pegUfFb2mebcZudmdVtAIM+eB5d0oUNmB1ze/3IMKxwW0zOJiIgoMaIZjvQvRhXbBKdWJfRwZGaUI5XPjno2cqMwXrrgpfD3P/NZHLjrAHIduWiX3g73nnIvzu7LZYmIiIhaMqM9YQ9BWcR7CXxvR6ZsL1gkr78euY3/MkUDipr3ZuSYN8aEPX9c5+MAKOtKCiGa9SwiIiJKjIhJmFB+q38J4Fgok/MFgMlSyp0mx9YijRoFRHrRccBTA7Bm75pmPcd+r29OV3Vjtbq9ZdIWdPmnr+Bqvj1fTfKklFEtBk5ERETJEzEJk1JKIcS7UsohABYkIKYWrWPHyG1+3vszAGWu1sCOA2N6TqNsBAD0zu8Nl/RV2i/KK8KBugPq/ntXvKdusyeMiIio9TA6J+wbIcRQUyNpJQoLI7fxVrT/cfyP+OHGH5r1vF9v+RVuj1vdb/dQO81i4COKRqjbHulhTxgREVErYXRO2B8A/FEIsRlANZQhSSmljK2bpxWbMcN42+bOBfPyKC+lAtAWaw0kIWER8an0T0REROYymoSdYWoUrUT//sl5rsujXfh7ePfh+Hrb18ENJTgcSURE1EqE7TYRQqQLISZBWZrodADbpJRbvB+Rbi6EOF0IsUEIsVEIMSVMu4uEEFIIURL1V5BAubnmP2PKx1MgpvsSKafTqdYbAwCH1YGvrvsq6Lo6Vx0aPY2atSWJiIio5Yo0dvUKgBIAq6H0hj1q9MZCCCuAp5qu6wfgMiFEP512OQD+AuBbo/dOloIErIc9a8Uszf6l/7tUs2+FVS1/IeBL1qYtmQYATMKIiIhaiUhJWD8p5ZVSyucAXARl7UijhgHYKKXcJKVsAPAWgHN12t0H4BEAdVHcOymM1AdrLimVSf2Tj5sMOU1i0e+LNOfT09Jx0fyLAACWpj++j379CM+teg4AMG7QOPODJCIiomaLlIQ1ejeklK5wDXV0B7DVb7+86ZhKCHEUgEOklO+Hu5EQYqIQolQIUbpnz54ow4ifSPXBYnH+m+dDTBfqh/fNx4eXP6wZlgSUXrDv//i9un9C0QkoerwI4/+nLBQ++tDRuOiIi+IfJBEREcVdpLGrQUKIiqZtASCjad/7dmS4WVJ6M8SlelIIC4DHAYyLFKSUcg6AOQBQUlIiIzSPk8RMcH/v1/ciN2ry/fjvUZRXpO6XV5ajzlWHwpxCZNgz8Nw5z8FmdGFLIiIiSqqwv7GllM0pOlUO4BC//UIA2/32cwD0B7C06Y2+LgAWCCHGSClLm/HcVsHpdOLx0sfVRbo/GvsRRh82GrZ7bXBLN96+8G112LFbZjdcf/T1mP/rfMz/1bccUlVDFTpnd8Z3f/wuKV8DERERxc7MbpOVAPoIIXoC2AZgLIDLvSellE4AHbz7QoilAO5oCwkYAOTPytfsjz5stLLR1M/XObezem57zXZM/3J60D1qXbXIsGWYFiMRERGZx7QkTErpEkLcBGARACuAF6WUPwsh7gVQKqVsc0sg5TyQgypXleaY3WLHofmHqvveavv+w47+bdV72XPgki7MPG2mSdESERGRmUydQCSl/ADABwHH/hGi7clmxtISBCZgaSIN9X+v1xzzJmFOp1NzfFTPUVh0te9NyRNePAEb9m3AicUnmhQtERERmYmzuJNATov8bsGYd8ao24EJGAA0uBu4TiQREVErxiSsBZmzco7aE7bZuVk97p+AuVwuHPqvQ1FRV4Ese1aiQyQiIqI4YRLWAkxaOAlPlD5hqO2/Sv8FZ50TXbK74KqBV5kcGREREZklUrFWipH/kkJfln2JfrODVmxSPfv9syHPDek0RLM/b+08AMCUEVPwtxP/1swoiYiIKFmYhCXACS+dgHX714U87/F4AAAXFF2gHsu3KyUsrFbtvK86Vx2y7FkYN3hc/AMlIiKihGESFmeBbzVm3O+r49U5szMe+sNDQdc0SmV1qHfK3lGPeaSSmKVb09Vj//zyn/ht/29cpJuIiCgF8Ld5nH269VMAynDklfOvRJ1bWZc805qJnXfu1LTNezAPVY1VQfcoyi7C/rr9AKBJuBZvXgwAXB+SiIgoBbAnLM5u+/g2dfuNNW+o29VTq9XtOSvn4Mr5V6KisQIeeILuseX2LepbkjarLwnbWbUTadY0PDr6UTNCJyIiogRiT1hIsS3gXe9Wiq/6J1cHJx1Ut0e+NBKflX2m7jusDrjcLnUNSS8plSQs05YJALj5g5ux+eBmZKWxLAUREVEqYBIWkoR/InbEEcauckmXZr9vu77o8XQPOBu0c8UEBNKt6XjtvNdw6TuXqmtG+p6uHHDYHACAr7d+DQB46NTgOWVERETU+nA40qC1a421c7u1PVorrlkRlIABwIdjP0TN1Bpc2P9CTQKWYVUm8te6awFA7fmyCOWP6upBV0cbOhEREbVA7AmLM5dH2xOWl5enbodarkj6ZWE1U2s0544pPAaAskxRniMPRERElBqYhOmYj9MQ65ywGpc2iSp6rChsezFdhN2f/NlkTP5sMqSU6JjZMaaYiIiIqOVhEqbjdVwT87VCCM3w4tbKrQCAeELjeAAAIABJREFUNEsahr8wXNN2TfmasPcqyinCwC4D1f2z+pwVc1xERETUsjAJ0+GCQ7PvcIRoqMMt3brHLR4Llpcvj3j9iutWYGj3ocYfSERERK0SJ+brqEGGZl/ENjIJAYEzDj0DcppEPepDtjuq01HqNhMwIiKitoFJmA4X0jT7RpMw23Rtx6KExIe/fRg0zyvQd3/6Lqr4iIiIqPVjEqYj1iQssOCqEZm2TBz25GFRX0dEREStG+eE6ahHFJPAohCqREWknjIiIiJKPewJ0+EKyE1jmRN26WGXavYtBr7VoZI0IiIiSj3sCdOxD/ma/UhJWLuH2uFgw0HNsbkb5gbcg71dRERE5MOeMB0HUKDZt4T4Lq0uWw0xXQQlYHqO6XZMPEIjIiKiFMEkTIcnoFp+qE6sk/9zsu5xOU1iUMdBAICC9ALIaRJfXfdVPEMkIiKiVo7DkTrcBt6OzHogK2iJIq8ej/VAWWUZACDDlqHbhoiIiNo29oTpCJwer5eEhUrAAKgJmAUWvHXxW3GMjIiIiFIFe8J0eAJy01jn1O+ftB95eXlxiIiIiIhSDZMwHRJWzX6kJKxbdjdsr9ruu56lJoiIiCgCDkfqkBEm5q8uW61ud83sqknAXj3nVVNjIyIiotTAnjAdMuDbYtV2jOHy9y73nRPak1cdfZW6PeXjKfjn8n9CBs0yIyIioraOSZgubdfXP/+pPbtm7xp1e0/dHnU7TWjfqnzsm8fggcfQE60BQ6BERESU2piE6dImYVddFaIZoHmVMrAqvlsqC3r/NP4nDCgaEK/giIiIKAUwCYujotwi5DyQgypXleY4EzAiIiIKxIn5zeXX+XVW77OCEjAiIiIiPUzC4ui0otPUbTlNqh9EREREgZiERcnpdIY8d/Y7ZycwEiIiImrNOCcsSp9u/VSzX++u1+xbYMGAjpwDRkREROExCYvSlMVTQp4rSC/Avsn7EhgNERERtVYcjoyge3ft/saDGzX76dZ0dZsJGBERERnFJCwkZUJ9ebnviN58sDp3XaICIiIiohTCJCwKq52rIzciIiIiMoBJWEgi6MhLq15KQhxERESUipiEhWG3a/f31+5PTiBERESUcpiEhVFcrN2vqK9IShxERESUepiEhWG1avc/K/ssZNsMa4bJ0RAREVEqYZ2wAGXIg3c+mHc40ul04oZFN+i257JEREREFAsmYQHewcXqtsOhfM6fla/b9vmzn09ESERERJSCOBwZoA6+4qvp6aHb/XX4XzFhyIQERERERESpiElYGOGSsFN7npq4QIiIiCjlMAkLcAC+CfaZmaHbndb7tAREQ0RERKmKSVgAJ3zzv15+Gfiy7MvkBUNEREQpy9QkTAhxuhBigxBioxBiis7524QQa4UQPwkhFgshepgZjxGVyG3aksjLY5V8IiIiModpSZgQwgrgKQBnAOgH4DIhRL+AZt8DKJFSDgTwNoBHzIrHqGpka/cbq4Pa2PhSKRERETWTmT1hwwBslFJuklI2AHgLwLn+DaSUS6SUNU273wAoNDEeQ3YiS7Nf76oPanP7cbcnKhwiIiJKUWYmYd0BbPXbL286FsoEAB+aGI8hDdAuGLlo46KgNjNGzUhUOERERJSizBxXEzrHdMvLCyGuBFAC4KQQ5ycCmAgARUVF8YpPVz20dSlqZa2pzyMiIqK2ycyesHIAh/jtFwLYHthICHEqgL8BGCOlDB77AyClnCOlLJFSlnTs2NGUYL12gWtAEhERkfnMTMJWAugjhOgphLADGAtggX8DIcRRAJ6DkoDtNjEWwzys2kFEREQJYFrGIaV0AbgJwCIA6wD8n5TyZyHEvUKIMU3N/gkgG8A8IcQPQogFIW6XMPXsCSMiIqIEMLXWgpTyAwAfBBz7h992i1v7x63mpRKry1YnNRYiIiJKXRx7C+CCQ90+7rXjkhgJERERpTImYQHcaKduV7uCC7UuG78skeEQERFRimISFiQr7NkRRSMSFAcRERGlMiZhQUJ/S4Z1HZbAOIiIiCiVMQkLoldjVvHtxG8TGAcRERGlMiZhBmWwdAURERHFEZOwIE09YZedpjl6aIdDkxALERERpSomYaH0WaLZzUzLTFIgRERElIqYhBmUbk2P3IiIiIjIICZhBl131HXJDoGIiIhSCJOwIPpvR/bs0DPBcRAREVEqYxJm0IC8AckOgYiIiFIIkzA954wN6hDLy8tLTixERESUkpiE6enF9SGJiIjIXEzCggjA0pDsIIiIiCjFMQkLIgDrvmQHQURERCnOluwAWiSWBCMiojhrbGxEeXk56urqkh0KmSA9PR2FhYVIS0szfA2TMD0y2QEQEVGqKS8vR05ODoqLiyGEfjkkap2klNi3bx/Ky8vRs6fxklYcjgziCFUqjIiIKGZ1dXVo3749E7AUJIRA+/bto+7lZBJGRESUIEzAUlcsf7ZMwgxIE8bHd4mIiFqqBx54AEceeSQGDhyIwYMH49tvvwUAFBcXY+/evUmOLrTvv/8e112nLB+4fv16HHfccXA4HJg5c6am3bXXXotOnTqhf//+hu67dOlS5OXlYfDgwRg8eDDuvfdeAEBDQwNOPPFEuFyu+H4hATgnzIAJgyckOwQiIqJmWb58Od5//3189913cDgc2Lt3LxoaWkdJpgcffBBTp04FABQUFODJJ5/Eu+++G9Ru3LhxuOmmm3D11VcbvvcJJ5yA999/X3PMbrdj5MiRmDt3Lq644ormBR8Ge8L0BHxXnhnzTHLiICIiipMdO3agQ4cOcDgcAIAOHTqgW7du6vnZs2fj6KOPxoABA7B+/XoAwIoVKzB8+HAcddRRGD58ODZs2AAAePnll3Huuefi9NNPx2GHHYbp06er93n99dcxbNgwDB48GDfccAPcbnez4q6srMRPP/2EQYMGAQA6deqEoUOH6r6FeOKJJ6KgoKBZz/M677zz8MYbb8TlXqGwJ4yIiCjRPvoI2Lkzvvfs0gU4/fSQp0eNGoV7770Xffv2xamnnopLL70UJ510knq+Q4cO+O677/D0009j5syZeP7553H44Yfjiy++gM1mw6effoq7774b8+fPB6AkaGvWrEFmZiaGDh2Ks846C1lZWZg7dy6++uorpKWl4cYbb8Qbb7wR1DN16623YsmSJUExjh07FlOmTNEcKy0tNTy8GIvly5dj0KBB6NatG2bOnIkjjzwSANC/f3+sXLnStOcCTMIi6p7dPdkhEBERNVt2djZWrVqFZcuWYcmSJbj00ksxY8YMjPv/9u49Oqoyzff49yEJpiJBxBBbiQIjdyQGSDgaUYMIIro6EHWhnIWh2x49MDLnsFpZ4hy6hQahe7h4vPaihQMKZ+Qol/agYpMWQRwHTAJERgnEHuxmCNqQMSYOKMh7/tg7ZaVyraSS4vL7rFWr9vXd735qp3h43137nTIFgLy8PACGDRvG+vXrAaisrCQ/P5+DBw9iZpw6dSpY3ujRo7nsssuC++7YsYP4+HiKiorIysoC4MSJE6Smptapy9KlS5td7/Lycrp169aic27K0KFD+fzzz+nUqRNvvfUW48eP5+DBgwDExcXRsWNHqqqqSE5ObpPjKwlrwuGfH451FURE5HzTSItVW4qLiyMnJ4ecnBwGDx7MqlWrgklYTTdlXFxc8Ib02bNnM3LkSDZs2MChQ4fIyckJlhX+a0AzwzlHfn4+CxYsaLQekbSEBQKBNnvAbefOnYPT48aNY9q0aRw7doyUlBQAvv32WxIT2+4J7krCRERELgClpaV06NCBPn36ALBnzx569OjR6D6VlZV07+71CK1cubLWui1btlBRUUEgEGDjxo2sWLGCpKQkcnNzmTFjBqmpqVRUVFBVVVXnOJG0hA0YMIDFixc3e/v6PPfccwA88sgjtZYfPXqUyy+/HDNj165dnDlzJti6d/z4cbp16xbRE/AjpSRMRETkAlBdXc306dP56quviI+Pp3fv3ixbtqzRfWbOnEl+fj5Llizh1ltvrbVuxIgRTJ48mbKyMiZNmkRmZiYA8+bNY8yYMZw5c4aEhASef/75JpO9xvTv35/Kyspgt+DRo0fJzMzk66+/pkOHDjz99NN88skndO7cmfvvv5/33nuPY8eOkZaWxpw5c3jwwQfZv38/N954Y52yX3/9dV588UXi4+MJBAK8+uqrwRa+rVu3Mm7cuBbXuznMuXNrjJ7MzExXWFjYZuWbAb8w76n5Bu6X51Z8RETk7PTpp58yYMCAWFcjKlauXElhYWGwhamtLV26lOTk5OCzwiJ11113sX79ejp27NjsffLy8liwYAH9+vVr9j71fcZmVuScy6xvez2iQkRERM5qU6dODd6z1hKbNm2KKAH77rvvGD9+fEQJWEuoJSyMWsJERKQtnE8tYVI/tYS12mkN4C0iIiJtTklYuMSvYl0DERERuQAoCQuX8FmsayAiIiIXACVh4a7+YYiCQFwghhURERGR85mSsHBd/hKcjLO4GFZEREQkuubPn8+gQYNIT08nIyODnTt3AtCzZ0+OHTsW49o1bPfu3cHHU6xZs4b09HTS09PJzs5m7969we1++tOfkpqa2uyxJvfv388NN9zARRddxKJFi2qta6isRx99lHfffbeVZ+RREhYu5YcPc/iVw2NYERERkej58MMP2bRpE8XFxZSUlFBQUMBVV10V62o1y1NPPcX06dMB6NWrF9u2baOkpITZs2fz0EMPBbebMmUKmzdvbna5Xbt25ZlnnuHRRx+ts66hsqZPn87ChQtbcBZ1KQkL1/sd7/0M/PEnf4xtXURERKKkvLyclJSU4PO2UlJSuPLKK4Prn332WYYOHcrgwYPZv38/ALt27SI7O5shQ4aQnZ1NaWkp4D2sNTc3l7Fjx9KvXz/mzJkTLGf16tUMHz6cjIwMHn74Yb7//vtW1buqqoqSkhKuu+46ALKzs7n00ksBuP766zl8+Icxnm+++Wa6du3a7LJTU1PJysqqd2iihsrq0aMHx48f5+jRo5GeSh0atiicIiIiIm1s82aIwr/htfzoR42PCz5mzBjmzp1L3759ue2225g4cSK33HJLcH1KSgrFxcW88MILLFq0iJdeeon+/fuzfft24uPjKSgo4IknnmDdunWAl6Dt27ePpKQksrKyuPPOO7n44otZu3YtH3zwAQkJCUybNo01a9bwwAMP1KpLJAN4FxYWNti9uHz5cu64447mhihqhg4dygcffMDdd9/dqnKUcoTTM8JEROQ81KlTJ4qKinj//ffZunUrEydOZOHChUyZMgXwhukBGDZsGOvXrwe8Abzz8/M5ePAgZsapU6eC5Y0ePTo42HVeXh47duwgPj6eoqIisrKyADhx4gSpqal16hLJAN7l5eV069atzvKtW7eyfPlyduzY0eyyoiU1NZUjR460uhwlYSIiIu2ssRarthQXF0dOTg45OTkMHjyYVatWBZOwmm7KuLg4Tp8+DcDs2bMZOXIkGzZs4NChQ+Tk5ATLqhnoOnTeOUd+fj4LFixotB6RtIQFAgFOnjxZa1lJSQk/+9nPePvtt4OJYHs6efIkgUDrn6CgJCxczTV1Jqa1EBERiarS0lI6dOhAnz59ANizZw89evRodJ/Kykq6d+8OePeBhdqyZQsVFRUEAgE2btzIihUrSEpKIjc3lxkzZpCamkpFRQVVVVV1jhNJS9iAAQNYvHhxcP7Pf/4zeXl5vPLKK/Tt27dZZdQMNP7II480+7iNOXDgAPfee2+ry9GN+SIiIheA6upq8vPzGThwIOnp6XzyySc8+eSTje4zc+ZMZs2axY033ljnBvsRI0YwefJkMjIyuPvuu8nMzGTgwIHMmzePMWPGkJ6ezujRoykvL29Vvfv3709lZSVVVVUAzJ07l+PHjzNt2jQyMjLIzPxhWMb777+fG264gdLSUtLS0li+fDngPYqivhazo0ePkpaWxpIlS5g3bx5paWl8/fXXjZZ16tQpysrKah23pTSAdxib80PzqgbvFhGRaDmfBvBeuXIlhYWFwRamtrZ06VKSk5ODzwqL1F133cX69evp2LFjq+uyYcMGiouL+dWvflVnnQbwFhERkfPK1KlTg/estcSmTZuikoABnD59mp///OdRKUv3hImIiEhEpkyZEryhvz0kJiYyefLkdjteY6JxL1gNtYSJiIiIxICSMBEREZEYUBImIiIiEgNKwkRERERiQEmYiIjIBWL+/PkMGjSI9PR0MjIy2LlzJwA9e/bk2LFjMa5dw3bv3h18PMXvf//7YP0zMzNrDVs0duxYunTpwl133dWscpcsWRJ8btqoUaP4/PPPmyzrvvvu4+DBg1E4qzZOwsxsrJmVmlmZmT1ez/qLzGytv36nmfVsy/qIiIhcqD788EM2bdpEcXExJSUlFBQUcNVVV8W6Ws3y1FNPMX36dABGjRrF3r172bNnDytWrKj17LDHHnuMV155pdnlDhkyhMLCQkpKSrjnnnuYOXNmk2VNnTqV3/zmN604mx+0WRJmZnHA88AdwEDgfjMbGLbZg8B/OOd6A0uBX7dVfURERC5k5eXlpKSkBJ+3lZKSwpVXXhlc/+yzzzJ06FAGDx7M/v37Adi1axfZ2dkMGTKE7OxsSktLAe9hrbm5uYwdO5Z+/foxZ86cYDmrV69m+PDhZGRk8PDDD9d50n6kqqqqKCkp4brrrgO8gchrxq385ptvao1hOWrUKJKTk5td9siRI0lKSgLg+uuv5/Dhw02WddNNN1FQUBAcX7M12vI5YcOBMufcnwDM7FUgF/gkZJtc4El/+nXgOTMzd649xl9ERCQCm8s2c7T6aFTL/FGnHzG2d8Mjg48ZM4a5c+fSt29fbrvtNiZOnMgtt9wSXJ+SkkJxcTEvvPACixYt4qWXXqJ///5s376d+Ph4CgoKeOKJJ1i3bh3gJWj79u0jKSmJrKws7rzzTi6++GLWrl3LBx98QEJCAtOmTWPNmjU88MADteoSyQDehYWFXHvttbWWbdiwgVmzZvHll1/y5ptvRhyr+ixfvpw77rijye06dOhA79692bt3L8OGDWvVMdsyCesO/CVk/jDwXxraxjl32swqgcuAWh3TZvYQ8BDA1Vdf3Vb1raXHRY0PaioiInIu6dSpE0VFRbz//vts3bqViRMnsnDhwuBDV/Py8gAYNmwY69evB7wBvPPz8zl48CBmxqlTp4LljR49OjgeY15eHjt27CA+Pp6ioiKysrIAOHHiBKmpqXXqEskA3uXl5XTr1q3WsgkTJjBhwgS2b9/O7NmzKSgoaH4g6rF69WoKCwvZtm1bs7ZPTU3lyJEjZ3USZvUsC2/has42OOeWAcvAGzuy9VVrmMaLFBGRttZYi1VbiouLIycnh5ycHAYPHsyqVauCSVhNN2VcXFywq2327NmMHDmSDRs2cOjQIXJycoJlhXYD1sw758jPz2fBggWN1iOSlrBAIMDJkyfrLefmm2/ms88+49ixY6SkpDR6zIYUFBQwf/58tm3b1uyhkU6ePEkgEGjR8UK1ZRJ2GAi94y8NONLANofNLB64BKhowzqJiIhckEpLS+nQoQN9+vQBYM+ePfTo0XivT2VlJd27dwe8+8BCbdmyhYqKCgKBABs3bmTFihUkJSWRm5vLjBkzSE1NpaKigqqqqjrHiaQlbMCAASxevDg4X1ZWxjXXXIOZUVxczHfffRdskWvIrFmzGD58OBMmTKi1fPfu3Tz88MNs3ry53ha7hhw4cIBBgwY1e/uGtGUS9hHQx8x6Af8O3AdMCtvmDSAf+BC4B3hX94OJiIhEX3V1NdOnT+err74iPj6e3r17s2zZskb3mTlzJvn5+SxZsoRbb7211roRI0YwefJkysrKmDRpEpmZmQDMmzePMWPGcObMGRISEnj++eebTPYa079/fyorK6mqqiI5OZl169bx8ssvk5CQQCAQYO3atcFWuZtuuon9+/dTXV1NWloay5cv5/bbb+fjjz/mxz/+cZ2yH3vsMaqrq4PjQV599dW88cYbjZb1xRdfEAgEuOKKK1p8TjWsLXMeMxsHPA3EASucc/PNbC5Q6Jx7w8wSgVeAIXgtYPfV3MjfkMzMTFdYWNhmdRYREWkLn376KQMGDIh1NaJi5cqVFBYW8txzz7XL8ZYuXUpycnKtx1FE4vbbb+edd96JWl06d+7Mgw8+WGddfZ+xmRU55zLrK6stW8Jwzr0FvBW27Bch0yeB6A1HLiIiIuedqVOn8tprr7V4/2glYABdunRh8uTJUSmrTVvC2oJawkRE5Fx0PrWESf0ibQnTsEUiIiIiMaAkTEREpJ2ca71P0nwt+WyVhImIiLSDxMREjh8/rkTsPOSc4/jx4yQmJka0X5vemC8iIiKetLQ0Dh8+zF//+tdYV0XaQGJiImlpaRHtoyRMRESkHSQkJNCrV69YV0POIuqOFBEREYkBJWEiIiIiMaAkTERERCQGzrmHtZrZX4HP2/gwKcCxNj7GhUYxjT7FNLoUz+hTTKNL8Yy+9ohpD+dct/pWnHNJWHsws8KGnm4rLaOYRp9iGl2KZ/QpptGleEZfrGOq7kgRERGRGFASJiIiIhIDSsLqtyzWFTgPKabRp5hGl+IZfYppdCme0RfTmOqeMBEREZEYUEuYiIiISAwoCQtjZmPNrNTMyszs8VjX52xmZofM7GMz22Nmhf6yrma2xcwO+u+X+svNzJ7x41piZkNDysn3tz9oZvmxOp9YMLMVZvalme0LWRa1GJrZMP8zKvP3tfY9w/bVQDyfNLN/96/TPWY2LmTdLD82pWZ2e8jyer8HzKyXme3047zWzDq239nFhpldZWZbzexTM/tXM/vv/nJdpy3QSDx1nbaQmSWa2S4z2+vHdI6/vN44mNlF/nyZv75nSFkRxbrVnHN6+S8gDvgM+BugI7AXGBjrep2tL+AQkBK27DfA4/7048Cv/elxwNuAAdcDO/3lXYE/+e+X+tOXxvrc2jGGNwNDgX1tEUNgF3CDv8/bwB2xPucYxPNJ4NF6th3o/41fBPTy//bjGvseAP4vcJ8//VtgaqzPuR1iegUw1J9OBg74sdN1Gt146jpteUwN6ORPJwA7/Wuv3jgA04Df+tP3AWtbGuvWvtQSVttwoMw59yfn3HfAq0BujOt0rskFVvnTq4DxIctfdp5/AbqY2RXA7cAW51yFc+4/gC3A2PaudKw457YDFWGLoxJDf11n59yHzvuGeTmkrPNSA/FsSC7wqnPuW+fcvwFleN8B9X4P+K0ztwKv+/uHfjbnLedcuXOu2J+uAj4FuqPrtEUaiWdDdJ02wb/Wqv3ZBP/laDgOodfu68AoP24RxToadVcSVlt34C8h84dp/I/jQueAP5hZkZk95C+73DlXDt6XDZDqL28otop5XdGKYXd/Onz5hegRv2tsRU23GZHH8zLgK+fc6bDlFwy/22YIXkuDrtNWCosn6DptMTOLM7M9wJd4Cf5nNByHYOz89ZV4cWv3f6eUhNVW330I+vlow250zg0F7gD+zsxubmTbhmKrmDdfpDFUbD0vAtcAGUA5sNhfrnhGwMw6AeuA/+Gc+7qxTetZpriGqSeeuk5bwTn3vXMuA0jDa7kaUN9m/vtZE1MlYbUdBq4KmU8DjsSoLmc959wR//1LYAPehf+F372A//6lv3lDsVXM64pWDA/70+HLLyjOuS/8L+gzwO/wrlOIPJ7H8LrW4sOWn/fMLAEvYVjjnFvvL9Z12kL1xVPXaXQ4574C3sO7J6yhOARj56+/BO82hnb/d0pJWG0fAX38X1R0xLth740Y1+msZGYXm1lyzTQwBtiHF6+aXz3lA7/3p98AHvB/OXU9UOl3YbwDjDGzS/3m9zH+sgtZVGLor6sys+v9+x0eCCnrglGTKPgm4F2n4MXzPv+XUr2APng3iNf7PeDfr7QVuMffP/SzOW/5185y4FPn3JKQVbpOW6CheOo6bTkz62ZmXfzpAHAb3r12DcUh9Nq9B3jXj1tEsY5K5aNxd//59ML7Zc8BvP7kf4h1fc7WF96vRPb6r3+tiRVev/ofgYP+e1d/uQHP+3H9GMgMKeuneDdAlgE/ifW5tXMc/wmv6+EU3v+2HoxmDIFMvC/zz4Dn8B/QfL6+GojnK368SvC+OK8I2f4f/NiUEvKLvIa+B/zrfpcf59eAi2J9zu0Q0xF4XS8lwB7/NU7XadTjqeu05TFNB3b7sdsH/KKxOACJ/nyZv/5vWhrr1r70xHwRERGRGFB3pIiIiEgMKAkTERERiQElYSIiIiIxoCRMREREJAaUhImIiIjEgJIwEYmYmX1vZntCXo+3sJyVZnZP01s2q6zxZjYwZH6umd0WhXJzzGxTyHR2a8sMKbunmU0Kmc80s2eiVb6InN3im95ERKSOE84bIqRdmVmcc+77BlaPBzYBnwA4537RBlXIAaqBf27uDmYW734Yvy5cT2AS8H8AnHOFQGHrqigi5wq1hIlIVJjZJWZWamb9/Pl/MrO/9aerzWyxmRWb2R/NrFs9+48ys91m9rE/gPFF/vJDZvYLM9sB3Gtmf2tmH5nZXjNbZ2ZJfuvUj4F/9FvmrgltZWui7Dl+vT42s/6NnF9P4L8BM/xj3OQ/qXudX5+PzOxGf9snzWyZmf0BeNlv8XrfP05xSGvaQuAmv7wZYa1uXc1so3kDOv+LmaWHlL3CzN4zsz+Z2d/7yy82szf9uOwzs4mt+0RFpK0pCRORlgiEdUdOdM5VAo8AK83sPuBS59zv/O0vBoqdN+D7NuCXoYWZWSKwEpjonBuM10o/NWSTk865Ec65V4H1zrks59x1eEOTPOic+2e8p4w/5pzLcM59FkHZx/x6vQg82tAJO+cOAb8FlvrHeB/4X/58FnA38FLILsOAXOfcJLxxFUf7x5kI1HQ5Pg6875e3NOyQc4Ddzrl04Ang5ZA4Dmd+AAACfUlEQVR1/YHb8cYX/KV5YxGOBY44565zzl0LbG7oXETk7KDuSBFpiXq7I51zW8zsXrxha64LWXUGWOtPrwbWh+3aD/g359wBf34V8HfA0/782pBtrzWzeUAXoBNNjzXaVNk1dSkC8pooK9xtwEBvOEAAOps/pireOH4n/OkE4DkzywC+B/o2o+wReIkdzrl3zewyM7vEX/emc+5b4Fsz+xK4HG/Im0Vm9mtgk58kishZTEmYiESNmXUABgAngK544zfWJ3y8NKt3qx98EzK9EhjvnNtrZlPw7tNqtFpNrP/Wf/+eyL8TOwA3hCRb3gG9pCy0zjOAL/AS0w7AyWaUXV+9a+L2bciy74F459wBMxuGN8bdAjP7g3NubrPOQkRiQt2RIhJNM/C6CO8HVvjdZOB919T8CnISsCNsv/1ATzPr7c9Pxuu2rE8yUO6X/V9Dllf568JFUnZTwo/xB7wuWAD8lq76XAKUO+fO+MePa6LOANvxz8/McvC6Tb9uqGJmdiXwn8651cAiYGhTJyMisaWWMBFpiYCZ7QmZ3wysAH4GDHfOVZnZduB/4t3/9Q0wyMyKgEq8+6KCnHMnzewnwGtmFg98hHf/VX1mAzuBz/G64GqSmFeB3/k3qgcfexFh2U35f8DrZpYLTAf+HnjezErwvk+34928H+4FYJ3fVbuVH1rJSoDTZrYXr4Vvd8g+TwL/2y/7P4H8Juo2GO+HCWeAU9S+701EzkLmXHivgIhIdJlZtXOuU6zrISJyNlF3pIiIiEgMqCVMREREJAbUEiYiIiISA0rCRERERGJASZiIiIhIDCgJExEREYkBJWEiIiIiMaAkTERERCQG/j80h/KCUeteTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"red\", \"blue\", \"green\"]\n",
    "labels = [\"Shape = (11, 5)\", \"Shape = (21, 11)\", \"Shape = (31, 21)\"]\n",
    "for i, shape in enumerate(shapes):\n",
    "    for j,run in enumerate(runs_scores[shape]):\n",
    "        if j == 0:\n",
    "            plt.plot(np.arange(min(len(run), 30000)), run[:min(len(run), 30000)],\n",
    "                     color = colors[i], alpha = 0.5, label = labels[i])\n",
    "        else:\n",
    "            plt.plot(np.arange(min(len(run), 30000)), run[:min(len(run), 30000)],\n",
    "                     color = colors[i], alpha = 0.5)\n",
    "\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xlabel(\"Exploration Iterations\")\n",
    "plt.ylabel(\"Progression\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 6)\n",
    "plt.savefig(\"experiments.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustification via Imitation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Best Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv(\"best_run.csv\", header = None)\n",
    "best_run1 = X.drop([1], axis = 1).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Environment Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action space : [left, up, right, down]\n",
    "\n",
    "Observation space : [x_position, y_position, distance to target, score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Environment(gym.Env):\n",
    "    def __init__(self, CORRIDOR_SHAPE = (21, 11), SEEDS = [42, 43, 44, 45],\n",
    "                 env = None,\n",
    "                 starting_position = (26, 26), starting_reward = 0, target_position = (22,19),\n",
    "                 MAX_SCORE = 1):\n",
    "        super(Environment, self).__init__()\n",
    "        self.CORRIDOR_SHAPE = CORRIDOR_SHAPE\n",
    "        self.SEEDS = SEEDS\n",
    "        if env is None:\n",
    "            self.env = create_env(self.CORRIDOR_SHAPE, self.SEEDS)\n",
    "        else:\n",
    "            self.env = env\n",
    "        self.MAX_SCORE = MAX_SCORE\n",
    "        self.size = 2*CORRIDOR_SHAPE[0] + CORRIDOR_SHAPE[1]\n",
    "        self.MAX_DIST = np.sqrt(2*self.size**2)\n",
    "        self.starting_position = np.array(starting_position)\n",
    "        self.starting_reward = starting_reward\n",
    "        self.target_position = np.array(target_position)\n",
    "        self.starting_distance = np.linalg.norm(self.starting_position - target_position)\n",
    "        \n",
    "        self.REWARD_VALUE = 11\n",
    "        self.STEP_PENALTY = 1\n",
    "        \n",
    "        #action space: [left, up, right, down]\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # obsevation space: [x_position, y_position, distance to target, score]\n",
    "        low = [0, 0, 0, 0]\n",
    "        high = [self.size, self.size, self.MAX_DIST, self.MAX_SCORE]\n",
    "        low = np.array(low)\n",
    "        high = np.array(high)\n",
    "        self.observation_space = spaces.Box(low, high)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env = create_env(self.CORRIDOR_SHAPE, self.SEEDS)        \n",
    "        self.current_state = np.array([self.starting_position[0], self.starting_position[1],\n",
    "                                       self.starting_distance, self.starting_reward])\n",
    "        return self._next_observation()\n",
    "    \n",
    "    def _next_observation(self):\n",
    "        self.current_state = np.array(self.current_state)\n",
    "        obs = self.current_state.copy()\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        self._take_action(action)\n",
    "        \n",
    "        x_pos = int(self.current_state[0])\n",
    "        y_pos = int(self.current_state[1])\n",
    "        reward = int(self.env[x_pos, y_pos] == REWARD_MAP_VALUE) * self.REWARD_VALUE - self.STEP_PENALTY\n",
    "        if reward >= 0:\n",
    "            self.env[x_pos, y_pos] = 0\n",
    "            self.current_state[3] += 1\n",
    "        \n",
    "        done = self.current_state[3] == self.MAX_SCORE\n",
    "        \n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "        x_pos = int(self.current_state[0])\n",
    "        y_pos = int(self.current_state[1])\n",
    "        x = int(x_pos)\n",
    "        y = int(y_pos)\n",
    "        \n",
    "        if action == 0:\n",
    "            # go left\n",
    "            if x_pos - 1 > 0:\n",
    "                if self.env[x_pos - 1, y_pos] != WALL_MAP_VALUE: \n",
    "                    x = x_pos - 1\n",
    "                \n",
    "        if action == 1:\n",
    "            # go up\n",
    "            if y_pos + 1 < self.env.shape[1]:\n",
    "                if self.env[x_pos, y_pos + 1] != WALL_MAP_VALUE:\n",
    "                    y = y_pos + 1\n",
    "                \n",
    "        if action == 2:\n",
    "            # go right\n",
    "            if x_pos + 1 < self.env.shape[0]:\n",
    "                if self.env[x_pos + 1, y_pos] != WALL_MAP_VALUE:\n",
    "                    x = x_pos + 1\n",
    "            \n",
    "        if action == 3:\n",
    "            # go down\n",
    "            if y_pos - 1 > 0:\n",
    "                if self.env[x_pos, y_pos - 1] != WALL_MAP_VALUE:\n",
    "                    y = y_pos - 1\n",
    "                \n",
    "        xy = np.array([x, y])\n",
    "                \n",
    "        distance_to_target = np.linalg.norm(xy - self.target_position)\n",
    "        self.current_state = np.array([x, y, distance_to_target, self.current_state[3]])\n",
    "        return\n",
    "    \n",
    "    def render(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Process (do not run / to be continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.policies import MlpLstmPolicy\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_demonstration(action_trajectory):\n",
    "    \"\"\"Creates the demonstration sequence from a sequence of actions\n",
    "       as required in the paper \"Learning Montezuma’s Revenge from a Single Demonstration\" \"\"\"\n",
    "    env = Environment()\n",
    "    env.reset()\n",
    "    demonstration = []\n",
    "    actions = []\n",
    "    game = create_env((21, 11))\n",
    "    env_states = []\n",
    "    agent_xy = [(26, 26)]\n",
    "\n",
    "    for action in action_trajectory:    \n",
    "        if(len(np.where(game == REWARD_MAP_VALUE)[0] > 0)):\n",
    "            state_t = env._next_observation()\n",
    "            action_t = action\n",
    "            state_t1, reward, done, _ = env.step(action)\n",
    "            x,y = agent_xy[-1]\n",
    "            if action == 0:\n",
    "                # go left\n",
    "                agent_xy.append((x-1,y))\n",
    "            if action == 1:\n",
    "                # go up\n",
    "                agent_xy.append((x,y+1))\n",
    "            if action == 2:\n",
    "                # go right\n",
    "                agent_xy.append((x+1,y))\n",
    "            if action == 3:\n",
    "                # go down\n",
    "                agent_xy.append((x,y-1))\n",
    "            if game[x,y] == REWARD_MAP_VALUE:      \n",
    "                game[x,y] = 0\n",
    "            env_states.append(game.copy())\n",
    "            demonstration.append(tuple([state_t, action_t, reward, state_t1, done, game.copy()]))\n",
    "    return demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration = make_demonstration(best_run1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Demo_Initialized_Rollout_Worker(demonstration, model, starting_point = -10,\n",
    "                                    batch_size = 32, memory_length = 10, batch_rollout_length = 30):\n",
    "    \n",
    "    state_t, action_t, reward_t, state_t1, done_t, env_state = demonstration[starting_point]\n",
    "    _, _, _, target_state, _, _ = demonstration[-1]\n",
    "    \n",
    "    MAX_SCORE = len(np.where(env_state == REWARD_MAP_VALUE)[0])\n",
    "    \n",
    "    env_kwargs = {\"env\": env_state,\n",
    "                  \"starting_position\" : state_t1[0:2],\n",
    "                  \"starting_reward\" : 0,\n",
    "                  \"target_position\" : target_state[0:2],\n",
    "                  \"MAX_SCORE\" : MAX_SCORE\n",
    "                 }\n",
    "    \n",
    "    success_counter = 0\n",
    "    batch = []\n",
    "    for j in range(batch_size):\n",
    "        model.set_env(make_vec_env(Environment, n_envs = 1, env_kwargs = env_kwargs))\n",
    "        env = model.env\n",
    "        env.reset()\n",
    "        sample = []\n",
    "        values = []\n",
    "        m = False\n",
    "        hidden_state = None\n",
    "        time_counter = starting_point - memory_length\n",
    "        for step in range(batch_rollout_length):\n",
    "            if time_counter < starting_point:\n",
    "                state_t, action_t, _, _, _, _ = demonstration[time_counter]\n",
    "                env = model.get_env()\n",
    "                state_t1, reward, done, _ = env.step([action_t])\n",
    "                m = False\n",
    "\n",
    "                action, hidden_state = model.predict(state_t.reshape(1, state_t.shape[0]), hidden_state)\n",
    "            else:\n",
    "                action_t, hidden_state = model.predict(sample[-1][0].reshape(1, state_t.shape[0]), hidden_state)\n",
    "                state_t1, reward, done, _ = env.step(action_t)\n",
    "                m = True\n",
    "\n",
    "            sample.append([state_t, action_t, reward, state_t1, done, m])\n",
    "            time_counter += 1\n",
    "            if done:\n",
    "                success_counter += 1\n",
    "        batch.append(sample)\n",
    "    return batch, success_counter\n",
    "                        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimizer(demonstration, model,\n",
    "              batch_size = 32, success_threshold = 0.5,\n",
    "              starting_point_shift = 10):\n",
    "    starting_point = -starting_point_shift\n",
    "    batch, success_counter = Demo_Initialized_Rollout_Worker(demonstration, model, starting_point)\n",
    "    batch = np.array(batch)\n",
    "    \n",
    "    \n",
    "    return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = make_vec_env(Environment, n_envs=1)\n",
    "\n",
    "model = PPO2(MlpLstmPolicy, env, verbose=1, nminibatches = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.zeros((30, 4))\n",
    "for j,state in enumerate(batch[0, :, 0]):\n",
    "    obs[j] = state\n",
    "values = np.zeros(30)\n",
    "masks = batch[0, :, 5]\n",
    "neglocpacs = np.zeros(30)\n",
    "for j,ob in enumerate(obs):\n",
    "    actions, states = model.predict([ob])\n",
    "    _, value, _, neglocpac = model.step(ob.reshape(1, 4), state = states, mask = [masks[j]])\n",
    "    values[j] = value[0]\n",
    "    neglocpacs[j] = neglocpac[0]\n",
    "    \n",
    "actions = np.zeros(30)\n",
    "for j,action in enumerate(batch[0, :, 1]):\n",
    "    try:\n",
    "        actions[j] = action[0]\n",
    "    except:\n",
    "        actions[j] = action\n",
    "        \n",
    "returns = np.zeros(30)\n",
    "for j,reward in enumerate(batch[0, :, 1]):\n",
    "    try:\n",
    "        returns[j] = reward[0]\n",
    "    except:\n",
    "        returns[j] = reward\n",
    "_, states = model.predict([ob])\n",
    "\n",
    "model._train_step(learning_rate = 1e-5, cliprange = 0.1,\n",
    "                  obs = obs, returns = returns, masks = masks,\n",
    "                  actions = actions, values = values, update = 0, states= states,\n",
    "                  neglogpacs = neglocpacs, writer = None)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
